<<<<<<< Updated upstream
#Pretty output
flextable(results, col_keys=c("Proclivity", "p_lr_total_0.01", "b_intercept_0.01", "CI_intercept", "p_lr_intercept_0.01", "b_predicted_class_1_0.01", "CI_class1", "p_lr_predicted_class_1_0.01", "b_predicted_class_2_0.01", "CI_class2", "p_lr_predicted_class_2_0.01")) %>%
set_formatter(p_lr_total_0.01=function(x) apa(x, decimals=3, leading=F),
b_intercept_0.01=function(x) format(round(exp(x), 2), nsmall=2), #transform into OR with exp()
p_lr_intercept_0.01=function(x) apa(x, decimals=3, leading=F),
b_predicted_class_1_0.01=function(x) format(round(exp(x), 2), nsmall=2),
p_lr_predicted_class_1_0.01=function(x) apa(x, decimals=3, leading=F),
b_predicted_class_2_0.01=function(x) format(round(exp(x), 2), nsmall=2),
p_lr_predicted_class_2_0.01=function(x) apa(x, decimals=3, leading=F)) %>%
set_header_labels(p_lr_total_0.01="p", b_intercept_0.01="Odds", CI_intercept="CI", p_lr_intercept_0.01="p", b_predicted_class_1_0.01="OR", CI_class1="CI", p_lr_predicted_class_1_0.01="p", b_predicted_class_2_0.01="OR", CI_class2="CI", p_lr_predicted_class_2_0.01="p") %>%
add_header_row(values=c("", "Global LRT", "(Intercept)", "Class 1", "Class 2"), colwidths=c(1, 1, 3, 3, 3)) %>%
theme_booktabs() %>%
autofit()
results <- cbind(Proclivity = c("Flirting or having sexual conversations via chat or webcam with a child", "Flirting or having sexual conversations via chat or webcam with a young person", "Driving under the influence of drugs/alcohol", "Paying or giving gifts to a child for online sexual material (for example, videos, images, or online streaming)", "Paying or giving gifts to a young person for online sexual material (for example, videos, images, or online streaming", "Killing someone", "Watching porn depicting a child", "Watch porn depicting a child on the Darknet", "Watching porn depicting a young person", "Engaging in sexual activity with a prostitute", "Watching porn in public spaces such as a bus or library", "Engaging in sexual activity with an adult who does not agree or is not able to agree, for example, due to intoxication", "Robbing a bank", "Having offline sex or sexual contact with a child", "Having offline sex or sexual contact with a young person", "Driving faster than the posted speed limit", "Engaging in sexual activity with an animal"), BCH_results_parameters %>%
filter(!str_detect(outcomes, "_red")) %>% #we do not want to show the additional analyses for the young persons after all
# filter(!outcomes %in% c("Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclPornYp_r", "Y_proclSexYp_r")) %>%
select(ends_with("total_0.01"), starts_with("b") & ends_with("0.01"), starts_with("p") & ends_with("0.01"), starts_with("ci") & ends_with("0.01")))
results$CI_intercept <- paste0("[", format(round(exp(results$ci_l_intercept_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_intercept_0.01), 2), nsmall=2), "]")
results$CI_class1 <- paste0("[", format(round(exp(results$ci_l_predicted_class_1_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_predicted_class_1_0.01), 2), nsmall=2), "]")
results$CI_class2 <- paste0("[", format(round(exp(results$ci_l_predicted_class_2_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_predicted_class_2_0.01), 2), nsmall=2), "]")
#Add odds for each class
results <- results %>% mutate(odds_predicted_class_1_0.01 = exp(results$b_intercept_0.01)*exp(results$b_predicted_class_1_0.01),
odds_predicted_class_2_0.01 = exp(results$b_intercept_0.01)*exp(results$b_predicted_class_2_0.01),
odds_predicted_class_3_0.01 = exp(results$b_intercept_0.01))
length(c(10, 11, 12, 17, 7, 8, 1, 4, 14, 9, 2, 5, 15, 16, 3, 13, 6))
#Put relevant results in a table
results <- cbind(Proclivity = c("Flirting or having sexual conversations via chat or webcam with a child", #1
"Flirting or having sexual conversations via chat or webcam with a young person", #2
"Driving under the influence of drugs/alcohol", #3
"Paying or giving gifts to a child for online sexual material (for example, videos, images, or online streaming)", #4
"Paying or giving gifts to a young person for online sexual material (for example, videos, images, or online streaming", #5
"Killing someone", #6
"Watching porn depicting a child", #7
"Watching porn depicting a child on the Darknet", #8
"Watching porn depicting a young person", #9
"Engaging in sexual activity with a prostitute", #10
"Watching porn in public spaces such as a bus or library", #11
"Engaging in sexual activity with an adult who does not agree or is not able to agree, for example, due to intoxication", #12
"Robbing a bank", #13
"Having offline sex or sexual contact with a child", #14
"Having offline sex or sexual contact with a young person", #15
"Driving faster than the posted speed limit", #16
"Engaging in sexual activity with an animal"), #17
BCH_results_parameters %>%
filter(!str_detect(outcomes, "_red")) %>% #we do not want to show the additional analyses for the young persons after all
# filter(!outcomes %in% c("Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclPornYp_r", "Y_proclSexYp_r")) %>%
select(ends_with("total_0.01"), starts_with("b") & ends_with("0.01"), starts_with("p") & ends_with("0.01"), starts_with("ci") & ends_with("0.01")))
#Create extra columns with CIs
results$CI_intercept <- paste0("[", format(round(exp(results$ci_l_intercept_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_intercept_0.01), 2), nsmall=2), "]")
results$CI_class1 <- paste0("[", format(round(exp(results$ci_l_predicted_class_1_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_predicted_class_1_0.01), 2), nsmall=2), "]")
results$CI_class2 <- paste0("[", format(round(exp(results$ci_l_predicted_class_2_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_predicted_class_2_0.01), 2), nsmall=2), "]")
#Add odds for each class
results <- results %>% mutate(odds_predicted_class_1_0.01 = exp(results$b_intercept_0.01)*exp(results$b_predicted_class_1_0.01),
odds_predicted_class_2_0.01 = exp(results$b_intercept_0.01)*exp(results$b_predicted_class_2_0.01),
odds_predicted_class_3_0.01 = exp(results$b_intercept_0.01))
#Change order of rows for unity with other tables
results <- results[c(10, 11, 12, 17, 7, 8, 1, 4, 14, 9, 2, 5, 15, 16, 3, 13, 6),]
#Pretty output
flextable(results, col_keys=c("Proclivity", "p_lr_total_0.01", "b_intercept_0.01", "CI_intercept", "p_lr_intercept_0.01", "b_predicted_class_1_0.01", "CI_class1", "p_lr_predicted_class_1_0.01", "b_predicted_class_2_0.01", "CI_class2", "p_lr_predicted_class_2_0.01")) %>%
set_formatter(p_lr_total_0.01=function(x) apa(x, decimals=3, leading=F),
b_intercept_0.01=function(x) format(round(exp(x), 2), nsmall=2), #transform into OR with exp()
p_lr_intercept_0.01=function(x) apa(x, decimals=3, leading=F),
b_predicted_class_1_0.01=function(x) format(round(exp(x), 2), nsmall=2),
p_lr_predicted_class_1_0.01=function(x) apa(x, decimals=3, leading=F),
b_predicted_class_2_0.01=function(x) format(round(exp(x), 2), nsmall=2),
p_lr_predicted_class_2_0.01=function(x) apa(x, decimals=3, leading=F)) %>%
set_header_labels(p_lr_total_0.01="p", b_intercept_0.01="Odds", CI_intercept="CI", p_lr_intercept_0.01="p", b_predicted_class_1_0.01="OR", CI_class1="CI", p_lr_predicted_class_1_0.01="p", b_predicted_class_2_0.01="OR", CI_class2="CI", p_lr_predicted_class_2_0.01="p") %>%
add_header_row(values=c("", "Global LRT", "(Intercept)", "Class 1", "Class 2"), colwidths=c(1, 1, 3, 3, 3)) %>%
theme_booktabs() %>%
autofit()
#Do not show code chunks in the knitted document
knitr::opts_chunk$set(echo=F, warning=F, message=F)
#For reproducible results
=======
packages <- c("tidyverse", "readr", "psych")
#load function to check whether required packages are installed.
source("./functions/check_required_packages.R")
check_required_packages(packages)
#load required packages
lapply(packages, require, character.only=T)
data <- haven::read_spss("./data/data raw/dataE_clear5 2209.sav") %>% select(CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr)
data <- haven::read_spss("./data/data_raw/dataE_clear5 2209.sav") %>% select(CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr)
View(data)
data <- haven::read_spss("./data/data_raw/dataE_clear5 2209.sav")
View(data)
colnames(data) %>% grep("y")
colnames(data) %>% grep("Y")
?starts_with()
data %>% select(starts_with("Y"))
data %>% select(starts_with("Y")) %>% colnames()
data %>% select(starts_with("Y")) %>% select(ends_with("r")) %>% head()
View(data)
data %>% select(CASE, starts_with("Y")) %>% select(CASE, ends_with("r")) %>% head()
data %>% select(CASE, starts_with("Y")) %>% select(CASE, ends_with("r")) %>% colnames()
data <- haven::read_spss("./data/data_raw/dataE_clear5 2209.sav") %>% select(CASE, starts_with("Y")) %>% select(CASE, ends_with("r"))
View(data)
?psych::fa()
tetrachoric(data %>% select(-CASE)) %>% psych::scree()
polychoric(data %>% select(-CASE)) %>% psych::scree()
polychoric(data %>% select(-CASE))
polychoric(data %>% select(-CASE)) %>% view()
polychoric(data %>% select(-CASE)) %>% as.matrix()
corr <- polychoric(data %>% select(-CASE)) %>% as.matrix()
View(corr)
corr <- polychoric(data %>% select(-CASE))
corr$rho
corr <- corr$rho
corr %>% class()
corr <- polychoric(data %>% select(-CASE))$rho
scree(polychoric(data %>% select(-CASE))$rho)
?psych::fa
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax")
install.packages("GPArotation")
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax")
summary(efa_3)
efa_3
print(efa_3, cut=.4, sort = T, digits=2)
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax", fm="old.min")
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax", fm="old.min", data=data %>% select(-CASE))
install.packages("jaspFactor")
efa_2 <- psych::fa(corr, nfactors=2, rotation="promax", fm="")
efa_2 <- psych::fa(corr, nfactors=2, rotation="promax")
load("C:/ARICA/WP3 RAs/Frederic/General_Assembly_2024/Relational_Analysis/.Rhistory")
save.image("C:/ARICA/WP3 RAs/Frederic/General_Assembly_2024/Relational_Analysis/.RData")
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "igraph")
#load required packages
lapply(packages, require, character.only=T)
#Define a function that takes the dataframe with topic_ids and vectors with member_ids of posters and returns a list of tibbles in which each unique possible combination of posters is reported in a combinations column.
get_unique_poster_tuples <- function(row, dataframe, column_of_poster_ids, column_of_topic_ids){
poster_vector <- dataframe %>% pull(column_of_poster_ids)
poster_vector <- poster_vector[[row]]
poster_dataframe <- expand_grid(names_1= poster_vector, names_2 = poster_vector) %>%
mutate(names_1 = as.numeric(names_1),
names_2 = as.numeric(names_2))
poster_dataframe <-  poster_dataframe %>%
mutate(combinations = lapply( 1:nrow(poster_dataframe),                                                                      function(x){c(poster_dataframe$names_1[x],poster_dataframe$names_2[x]) %>% sort()})) %>%
filter(names_1 != names_2) %>%
distinct(combinations, .keep_all = TRUE)
topic_id <- dataframe %>% pull(column_of_topic_ids)
topic_id <- rep(topic_id[[row]], times=nrow(poster_dataframe))
poster_dataframe <- poster_dataframe %>% mutate(topic_id = topic_id)
return(poster_dataframe)
}
#Enter the list of tibbles to our topic_network tibble.
posters_in_topic <- lapply(1:nrow(topic_network), get_unique_poster_tuples, dataframe=topic_network, column_of_poster_ids = "posters", column_of_topic_ids = "topic_id")
#We load the required data from the phpbb_total.sav file in the pedleaks folder.
cols <- c("post_id", "member_id", "topic_id", "forum_id", "post_original", "post_reply", "post_time")
data <- haven::read_spss("./data/phpbb_posts nested within members.sav") %>% select(all_of(cols))
"C:\ARICA\WP3 RAs\Frederic\General_Assembly_2024\Relational_Analysis\data\phpbb_posts nested within members.sav"
#We load the required data from the phpbb_total.sav file in the pedleaks folder.
cols <- c("post_id", "member_id", "topic_id", "forum_id", "post_original", "post_reply", "post_time")
data <- haven::read_spss("./data/phpbb_posts nested within members.sav") %>% select(all_of(cols))
topic_network <- data %>% as_tibble()%>% group_by(topic_id) %>% summarize(posters = stringr::str_c(member_id, collapse=",")) %>% mutate(posters = str_split(posters, pattern=","))
#Define a function that takes the dataframe with topic_ids and vectors with member_ids of posters and returns a list of tibbles in which each unique possible combination of posters is reported in a combinations column.
get_unique_poster_tuples <- function(row, dataframe, column_of_poster_ids, column_of_topic_ids){
poster_vector <- dataframe %>% pull(column_of_poster_ids)
poster_vector <- poster_vector[[row]]
poster_dataframe <- expand_grid(names_1= poster_vector, names_2 = poster_vector) %>%
mutate(names_1 = as.numeric(names_1),
names_2 = as.numeric(names_2))
poster_dataframe <-  poster_dataframe %>%
mutate(combinations = lapply( 1:nrow(poster_dataframe),                                                                      function(x){c(poster_dataframe$names_1[x],poster_dataframe$names_2[x]) %>% sort()})) %>%
filter(names_1 != names_2) %>%
distinct(combinations, .keep_all = TRUE)
topic_id <- dataframe %>% pull(column_of_topic_ids)
topic_id <- rep(topic_id[[row]], times=nrow(poster_dataframe))
poster_dataframe <- poster_dataframe %>% mutate(topic_id = topic_id)
return(poster_dataframe)
}
#Enter the list of tibbles to our topic_network tibble.
posters_in_topic <- lapply(1:nrow(topic_network), get_unique_poster_tuples, dataframe=topic_network, column_of_poster_ids = "posters", column_of_topic_ids = "topic_id")
topic_network <- topic_network %>% mutate(posters_in_topic = posters_in_topic)
#Enter a column with the number of posters in every topic
topic_network <- topic_network %>% mutate(n_posters = topic_network$posters %>% lapply(length))
rm(posters_in_topic)
#Filter out all values in which only one person has posted in the topic. In a network they would end up being dots without connections. We save them in a serperate tibble however, if one wishes to analyse them later on.
topic_network_unanswered_topics <- topic_network %>% filter(n_posters <  2)
topic_network_answered_topics <- topic_network %>% filter(n_posters > 1)
#We remove the topic_network tibble. We can always recreate it by combining the topic_network_answered_topics and topic_network_unanswered_topics tibbles.
rm(topic_network)
#We combine the tibbles of unique combinations of posters in all topics by column.
test <- map_dfr(topic_network_answered_topics$posters_in_topic, bind_rows)
#We now have a table that tells us who posts together in a topic. However we do not yet know who DOESN'T post together.
# To DO: Look up how an edge lists object has to look like in igraph. Find a way to add all posters who engage in threads with more than one post together and create a dummy variable with people who post together in one topic and people who do not post together in a topic. Maybe consider using group_by name_1 or something and sum to create a weighed edge list.
test_summary <- test %>% group_by(combinations) %>% reframe(combinations = combinations,topic_id = topic_id, n = n())
name_1 <- lapply(1:nrow(test_summary), function(x){test_summary$combinations[[x]][1]}) %>% flatten() %>% unlist()
name_2 <- lapply(1:nrow(test_summary), function(x){test_summary$combinations[[x]][2]}) %>% flatten() %>% unlist()
test_summary <- test_summary %>%  mutate(names_1 = name_1, names_2 = name_2)
test_summary <- test_summary %>% group_by(combinations) %>% reframe(topic_ids = paste(topic_id, collapse=","), n=n, names_1 = names_1, names_2 = names_2) %>% distinct()
test_summary <- test_summary %>% mutate(topic_ids = lapply(1:nrow(test_summary), function(x){test_summary$topic_ids[[x]] %>% str_split_1(",") %>% as.numeric()}))
#We combine the tibbles of unique combinations of posters in all topics by column.
topic_network_edges <- map_dfr(topic_network_answered_topics$posters_in_topic, bind_rows)
#We now have a table that tells us who posts together in a topic. However we do not yet know who DOESN'T post together.
# To DO: Look up how an edge lists object has to look like in igraph. Find a way to add all posters who engage in threads with more than one post together and create a dummy variable with people who post together in one topic and people who do not post together in a topic. Maybe consider using group_by name_1 or something and sum to create a weighed edge list.
topic_network_edges <- topic_network_edges %>% group_by(combinations) %>% reframe(combinations = combinations,topic_id = topic_id, n = n())
name_1 <- lapply(1:nrow(topic_network_edges), function(x){topic_network_edges$combinations[[x]][1]}) %>% flatten() %>% unlist()
name_2 <- lapply(1:nrow(topic_network_edges), function(x){topic_network_edges$combinations[[x]][2]}) %>% flatten() %>% unlist()
topic_network_edges <- topic_network_edges %>%  mutate(names_1 = name_1, names_2 = name_2)
topic_network_edges <- topic_network_edges %>% group_by(combinations) %>% reframe(topic_ids = paste(topic_id, collapse=","), n=n, names_1 = names_1, names_2 = names_2) %>% distinct()
topic_network_edges <- topic_network_edges %>% mutate(topic_ids = lapply(1:nrow(topic_network_edges), function(x){topic_network_edges$topic_ids[[x]] %>% str_split_1(",") %>% as.numeric()}))
#topic_network_edges is the output of our data wrangling. It includes a weighted undirected edgelist, that who posted in the same topics in pedoleaks (nodes = names_1, names_2; edge_weights = n). We know which topics these were, because a vector for each unique combination of users, who posted in the same topic, the ids of the common topics saved in the column "topic_ids".
rm(test, test_summary, efa_3, corr)
View(topic_network_edges)
topic_network <- list("answered_topics" = topic_network_answered_topics, "unanswered_topics" =topic_network_unanswered_topics, "edges_at" = topic_network_edges)
rm(topic_network_answered_topics, topic_network_edges, topic_network_unanswered_topics)
topic_network[["edges_at"]]
g <- graph_from_data_frame(topic_network[["edges_at"]] %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
View(g)
print(g, e=TRUE, v=TRUE)
g <- graph_from_data_frame(topic_network[["edges_at"]] %>% select(names_1, names_1, n) %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
g <- graph_from_data_frame(topic_network[["edges_at"]] %>% select(names_1, names_2, n) %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
print(g, e=TRUE, v=TRUE)
attr(g, "weight")
attributes(g)
E(g)
topic_network[["edges_at"]] %>% pull(n)
E(g)$weight <- topic_network[["edges_at"]] %>% pull(n)
print(g, e=TRUE, v=TRUE)
is_weighted(g)
vertex_connectivity(g)
degree(g, v=V(g))
degree(g, v=V(g)) %>% view()
topic_graph <- graph_from_data_frame(topic_network[["edges_at"]] %>% select(names_1, names_2, n) %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
E(topic_graph)$weight <- topic_network[["edges_at"]] %>% pull(n)
print(g, e=TRUE, v=TRUE)
View(topic_network)
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph)) %>% as.tibble() %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph)) %>% as_tibble() %>% rownames_to_column("user_id")
View(centrality_topic_graph)
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph)) %>% as.tibble() %>% rename(degree = value) %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))  %>% rename(degree = value) %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))  %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))
centrality_topic_graph %>% class()
rownames(centrality_topic_graph)
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))
centrality_topic_graph %>% rownames()
centrality_topic_graph %>% attributes()
centrality_topic_graph %>% names()
degree(topic_graph, v=V(topic_graph))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph))$names, "degree" = degree(topic_graph, v=V(topic_graph)))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph)))
View(centrality_topic_graph)
degree(topic_graph, v=V(topic_graph), normalized=T)
betweenness(topic_graph)
strength(topic_graph)
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph))) %>% mutate(degree_centralized = degree(topic_graph, v=V(topic_graph), centralized=T), weigthed_degree = strength(topic_graph), weighted_degree_centralized = strength(topic_graph, centralized=T))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph))) %>% mutate(degree_normalized = degree(topic_graph, v=V(topic_graph), normalized = T), weigthed_degree = strength(topic_graph), weighted_degree_normalized = strength(topic_graph, normalized=T))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph))) %>% mutate(degree_normalized = degree(topic_graph, v=V(topic_graph), normalized = T), weigthed_degree = strength(topic_graph))
vertex_connectivity(topic_graph)
View(centrality_topic_graph)
load("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/LCA_analysis.Rmd")
load("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM")
#load function to check whether required packages are installed.
source("./functions/check_required_packages.R")
check_required_packages(packages)
#load required packages
lapply(packages, require, character.only=T)
#######ATTENTION:
#At this point I load a presaved RData variables in which the  environment is saved. That makes the code less reproduceable, but removing the eval=FALSE specifications in all code blocks will make that possible.
load(".RData")
options(scipen = 999)
View(prob_table_LCA_m)
prob_table_LCA_m <- reshape(prob_table_LCA_m, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
View(prob_table_LCA_m)
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category")) %>% view()
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
prob_table_LCA_f <- table_prob(lca_final_model_f)
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
View(data)
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
install.packages("foreign")
prob(lca_final_model_m, type="individual")
library(tidyverse)
library(tidySEM)
prob(lca_final_model_m, type="individual")
class_prob(lca_final_model_m, type="individual")
posterior_probabilities <-  class_prob(lca_final_model_m, type="individual") %>% as_tibble()
posterior_probabilities
posterior_probabilities %>% colnames()
posteriors <-  class_prob(lca_final_model_m, type="individual") %>% as_tibble()
rm(posterior_probabilities)
length(posteriors)
nrow(posteriors)
ncol(posteriors)
posterios
posteriors
posteriorsstr()
posteriors %>% str()
class_prob(lca_final_model_m, type="individual") %>% str()
class_prob(lca_final_model_m, type="individual") %>% unlist()
class_prob(lca_final_model_m, type="individual") %>% flatten() %>% str()
class_prob(lca_final_model_m, type="individual") %>% str()
class_prob(lca_final_model_m, type="individual")$individual %>% str()
class_prob(lca_final_model_m, type="individual")$individual %>% as_tibble() %>% str()
posteriors <- class_prob(lca_final_model_m, type="individual")$individual %>% as_tibble()
posteriors %>% str()
posteriors %>% colnames()
posteriors %>% ncol()
ncol(posteriors)^2
ncol(posteriors - 1)^2
(ncol(posteriors)-1)^2
posteriors$predicted
#creating the weights needed for the D matrix calculation
n<-length(nrow(posteriors)) # the length of the data file
n_class <- ncol(posteriors)-1) #number of classes in the lca solution
ctm<-matrix(nrow=n,ncol=n_class^2)#modal weights 3*3 class
ctp<-matrix(nrow=n,ncol=n_class^2)#proportional weights 3*3 class
modal<-matrix(nrow=n, ncol=n_class^2) #modal class assignment 3 dummies for 3 classes
for (j in 1:n_class) # creating dummies for modal posterior class assignment
{
modal[,j]<- ifelse (posteriors$predicted==j, 1, 0)
}
n_class <- ncol(posteriors-1) #number of classes in the lca solution
ctm<-matrix(nrow=n,ncol=n_class^2)#modal weights 3*3 class
ctp<-matrix(nrow=n,ncol=n_class^2)#proportional weights 3*3 class
modal<-matrix(nrow=n, ncol=n_class^2) #modal class assignment 3 dummies for 3 classes
for (j in 1:n_class) # creating dummies for modal posterior class assignment
{
modal[,j]<- ifelse (posteriors$predicted==j, 1, 0)
}
n
nrow(posteriors)
#creating the weights needed for the D matrix calculation
n<-nrow(posteriors) # the length of the data file
n_class <- ncol(posteriors-1) #number of classes in the lca solution
ctm<-matrix(nrow=n,ncol=n_class^2)#modal weights 3*3 class
ctp<-matrix(nrow=n,ncol=n_class^2)#proportional weights 3*3 class
modal<-matrix(nrow=n, ncol=n_class^2) #modal class assignment 3 dummies for 3 classes
for (j in 1:n_class) # creating dummies for modal posterior class assignment
{
modal[,j]<- ifelse (posteriors$predicted==j, 1, 0)
}
view(modal)
#creating the weights needed for the D matrix calculation
n<-nrow(posteriors) # the length of the data file
n_class <- ncol(posteriors-1) #number of classes in the lca solution
ctm<-matrix(nrow=n,ncol=n_class)#modal weights 3*3 class
ctp<-matrix(nrow=n,ncol=n_class)#proportional weights 3*3 class
modal<-matrix(nrow=n, ncol=n_class) #modal class assignment 3 dummies for 3 classes
for (j in 1:n_class) # creating dummies for modal posterior class assignment
{
modal[,j]<- ifelse (posteriors$predicted==j, 1, 0)
}
view(modal)
n_class
#creating the weights needed for the D matrix calculation
n<-nrow(posteriors) # the length of the data file
n_class <- ncol(posteriors)-1 #number of classes in the lca solution
ctm<-matrix(nrow=n,ncol=n_class)#modal weights 3*3 class
ctp<-matrix(nrow=n,ncol=n_class)#proportional weights 3*3 class
modal<-matrix(nrow=n, ncol=n_class) #modal class assignment 3 dummies for 3 classes
for (j in 1:n_class) # creating dummies for modal posterior class assignment
{
modal[,j]<- ifelse (posteriors$predicted==j, 1, 0)
}
modal
view(ctm)
??elementwise
posteriors %>% select(-1)
posteriors %>% select(-predicted) %>% as_matrix
posteriors %>% select(-predicted) %>% as_matrix()
posteriors %>% select(-predicted) %>% as.matrix()
(posteriors %>% select(-predicted) %>% as.matrix())*modal
modla
modal
?solve()
modal
# obtaining the elements of the D matrix
ctm <- (posteriors %>% select(-predicted) %>% as.matrix())*modal
combined <- c(modal, ctm)
combined
combined <- cbind(modal, ctm)
combined
combined %>% str(+)
combined %>% str()
combined %>% class()
colSums(cobined)
colSums(combined)
class_prob(lca_final_model_m, type="avg.mostlikely")
modal %>% head()
combined %>% head()
apply(combined,2,sum)
apply(combined,2,sum) %>% cbind() %>% class()
apply(combined,2,sum) %>% cbind() %>% str()
apply(combined,2,sum) %>% str()
colSums()
COLSUMS
COLSUMS<- apply(combined,2,sum) %>% cbind() #summing all the weights
COLSUMS
4:12 %>% length()
ctm
apply(posteriors %>% select(-predicted),1,which.max)
posteriors <- class_prob(lca_final_model_m, type="individual")$individual %>% select(-predicted)
modclass <- apply(posteriors,1,which.max)
nclass=3
Ptable <- cbind(posteriors, modclass)
Pmatrix <- matrix(0, nclass, nclass)
Npmatrix <- matrix(0, nclass, nclass)
for (i in 1:nclass){
for (j in 1:nclass){
Pmatrix[i,j]<-sum(subset(Ptable, modclass==i)[,j])
Npmatrix[i,j] <- Pmatrix[i,j]*table(modclass)[i]
}
}
view(Npmatrix)
view(Pmatrix)
table(modclass)
modclass
posteriors <- class_prob(lca_final_model_m, type="individual")$individual %>% select(-predicted)
posteriors <- class_prob(lca_final_model_m, type="individual")$individual %>% select(-predicted)
posteriors <- class_prob(lca_final_model_m, type="individual")$individual %>% as_tibble() %>% select(-predicted)
modclass <- apply(posteriors,1,which.max)
nclass=3
Ptable <- cbind(posteriors, modclass)
Pmatrix <- matrix(0, nclass, nclass)
Npmatrix <- matrix(0, nclass, nclass)
for (i in 1:nclass){
for (j in 1:nclass){
Pmatrix[i,j]<-sum(subset(Ptable, modclass==i)[,j])
Npmatrix[i,j] <- Pmatrix[i,j]*table(modclass)[i]
}
}
view(Npmatrix)
view(Pmatrix)
denom<-colSums(Npmatrix)
Qmatrix<-matrix(0, nclass, nclass)
for (i in 1:nclass){
for (j in 1:nclass){
Qmatrix[j,i]<-Npmatrix[i,j]/denom[j]
}
}
view(Qmatrix)
sum(subset(Ptable,modclass==1)
)
sum(subset(Ptable,modclass==1)[,1])
subset(Ptable,modclass==1)[,1]
subset(Ptable,modclass==1)
table(modclass)[1]
iD <- solve(Qmatrix)
View(iD)
combined
DIM <- solve(Qmatrix)
#final modal bch weights applied to each case i
wm1<- ((combined[,1]*DIM[1,1]) + ( combined[,2]
*DIM[2,1]) + (combined[,3]*DIM[3,1]))
wm2<- ((combined[,1]*DIM[1,2]) + (combined[,2]
*DIM[2,2]) + (combined[,3]*DIM[3,2]))
wm3<- ((combined[,1]*DIM[1,3]) + ( combined[,2]
*DIM[2,3]) + (combined[,3]*DIM[3,3]))
wm1 %>% length()
#create and save long file
class_longa<-data.frame (wmodal1=combined[,1],
wmodal2=combined[,2],
wmodal3=combined[,3],
wbchmodal1=wm1, wbchmodal2=wm2,
bchmodal3=wm3)
install.packages("Hmisc")
library(Hmisc)
View(class_longa)
#create and save long file
class_longa<-data.frame (wmodal1=combined[,1],
wmodal2=combined[,2],
wmodal3=combined[,3],
wbchmodal1=wm1, wbchmodal2=wm2,
wbchmodal3=wm3)
class_long<- reShape(class_longa, base=c("wmodal","wbchmodal"),reps=3)
View(class_long)
View(class_longa)
View(combined)
wm1
wm1[1]
(combined[,1]*DIM[1,1]) + ( combined[,2]
*DIM[2,1]) + (combined[,3]*DIM[3,1])
DIM %>% head()
DIM[1,1]
knitr::opts_chunk$set(echo = TRUE)
#for reproducible results
>>>>>>> Stashed changes
set.seed(100)
#Turn off scientific notification
options(scipen=999)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM", "MOTE", "flextable", "logistf")
#Load function to check whether required packages are installed & load required packages
source("./functions/check_required_packages.R")
check_required_packages(packages)
lapply(packages, require, character.only=T)
#Clean up
rm(packages)
#######ATTENTION!!!
#At this point we load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=F specifications in all code blocks will make that possible
load(".RData")
#Put relevant results in a table
results <- cbind(Proclivity = c("Flirting or having sexual conversations via chat or webcam with a child", #1
"Flirting or having sexual conversations via chat or webcam with a young person", #2
"Driving under the influence of drugs/alcohol", #3
"Paying or giving gifts to a child for online sexual material (for example, videos, images, or online streaming)", #4
"Paying or giving gifts to a young person for online sexual material (for example, videos, images, or online streaming", #5
"Killing someone", #6
"Watching porn depicting a child", #7
"Watching porn depicting a child on the Darknet", #8
"Watching porn depicting a young person", #9
"Engaging in sexual activity with a prostitute", #10
"Watching porn in public spaces such as a bus or library", #11
"Engaging in sexual activity with an adult who does not agree or is not able to agree, for example, due to intoxication", #12
"Robbing a bank", #13
"Having offline sex or sexual contact with a child", #14
"Having offline sex or sexual contact with a young person", #15
"Driving faster than the posted speed limit", #16
"Engaging in sexual activity with an animal"), #17
BCH_results_parameters %>%
filter(!str_detect(outcomes, "_red")) %>% #we do not want to show the additional analyses for the young persons after all
# filter(!outcomes %in% c("Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclPornYp_r", "Y_proclSexYp_r")) %>%
select(ends_with("total_0.01"), starts_with("b") & ends_with("0.01"), starts_with("p") & ends_with("0.01")
#, starts_with("ci") & ends_with("0.01")
))
# #Create extra columns with CIs
# results$CI_intercept <- paste0("[", format(round(exp(results$ci_l_intercept_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_intercept_0.01), 2), nsmall=2), "]")
# results$CI_class1 <- paste0("[", format(round(exp(results$ci_l_predicted_class_1_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_predicted_class_1_0.01), 2), nsmall=2), "]")
# results$CI_class2 <- paste0("[", format(round(exp(results$ci_l_predicted_class_2_0.01), 2), nsmall=2), ", ", format(round(exp(results$ci_r_predicted_class_2_0.01), 2), nsmall=2), "]")
#Add odds for each class
results <- results %>% mutate(odds_predicted_class_1_0.01 = exp(results$b_intercept_0.01)*exp(results$b_predicted_class_1_0.01),
odds_predicted_class_2_0.01 = exp(results$b_intercept_0.01)*exp(results$b_predicted_class_2_0.01),
odds_predicted_class_3_0.01 = exp(results$b_intercept_0.01))
#Change order of rows for unity with other tables
results <- results[c(10, 11, 12, 17, 7, 8, 1, 4, 14, 9, 2, 5, 15, 16, 3, 13, 6),]
#Pretty output
flextable(results, col_keys=c("Proclivity", "p_lr_total_0.01", "b_intercept_0.01",
#"CI_intercept",
"p_lr_intercept_0.01", "b_predicted_class_1_0.01",
#"CI_class1",
"p_lr_predicted_class_1_0.01", "b_predicted_class_2_0.01",
#"CI_class2",
"p_lr_predicted_class_2_0.01")) %>%
set_formatter(p_lr_total_0.01=function(x) apa(x, decimals=3, leading=F),
b_intercept_0.01=function(x) format(round(exp(x), 2), nsmall=2), #transform into OR with exp()
p_lr_intercept_0.01=function(x) apa(x, decimals=3, leading=F),
b_predicted_class_1_0.01=function(x) format(round(exp(x), 2), nsmall=2),
p_lr_predicted_class_1_0.01=function(x) apa(x, decimals=3, leading=F),
b_predicted_class_2_0.01=function(x) format(round(exp(x), 2), nsmall=2),
p_lr_predicted_class_2_0.01=function(x) apa(x, decimals=3, leading=F)) %>%
set_header_labels(p_lr_total_0.01="p", b_intercept_0.01="Odds",
#CI_intercept="CI",
p_lr_intercept_0.01="p", b_predicted_class_1_0.01="OR",
#CI_class1="CI",
p_lr_predicted_class_1_0.01="p", b_predicted_class_2_0.01="OR",
#CI_class2="CI",
p_lr_predicted_class_2_0.01="p") %>%
add_header_row(values=c("", "Global LRT", "(Intercept)", "Class 1", "Class 2"), colwidths=c(1, 1, 2, 2, 2)) %>%
theme_booktabs() %>%
autofit()
View(results)
#Pivot results table for plotting
#Only odds < 1 for better scaling
plot_results <- results %>%
select(Proclivity, starts_with("odds")) %>%
filter(odds_predicted_class_1_0.01 < 1 & odds_predicted_class_2_0.01 < 1 & odds_predicted_class_3_0.01 < 1) %>%
pivot_longer(cols=starts_with("odds"), names_to="class", values_to="odds")
#Rename class column
plot_results$class <- rep(1:3, nrow(plot_results)/3)
#Remaining odds > 1
plot_results_2 <- results %>%
select(Proclivity, starts_with("odds")) %>%
filter(odds_predicted_class_1_0.01 > 1 | odds_predicted_class_2_0.01 > 1 | odds_predicted_class_3_0.01 > 1) %>%
pivot_longer(cols=starts_with("odds"), names_to="class", values_to="odds")
#Rename class column
plot_results_2$class <- rep(1:3, nrow(plot_results_2)/3)
#Line plots
#Odds < 1
ggplot(plot_results, aes(x=Proclivity, y=odds, group=as.factor(class), linetype=as.factor(class))) +
geom_line() +
geom_point(aes(shape=as.factor(class))) +
scale_linetype_manual(name=NULL, values=c("dotted", "dashed", "solid"), labels=c("Class 1", "Class 2", "Class 3")) +
scale_shape_manual(name=NULL, values=c(0,  3, 1)) +
guides(shape="none") +
theme_classic() +
theme(axis.text.x=element_text(angle=45, hjust=1, size=8))
#Odds > 1
ggplot(plot_results_2, aes(x=Proclivity, y=odds, group=as.factor(class), linetype=as.factor(class))) +
geom_line() +
geom_point(aes(shape=as.factor(class))) +
scale_linetype_manual(name=NULL, values=c("dotted", "dashed", "solid"), labels=c("Class 1", "Class 2", "Class 3")) +
scale_shape_manual(name=NULL, values=c(0,  3, 1)) +
guides(shape="none") +
theme_classic() +
theme(axis.text.x=element_text(angle=45, hjust=1, size=8))
# #Alternative: bar plots
# #Make a list of barplots with odds < 1
# plots <- lapply(plot_results$Proclivity %>% unique(), function(x){
#   ggplot(plot_results %>% filter(Proclivity == x), aes(x=class, y=odds, fill=as.factor(class))) +
#   scale_fill_manual(name=NULL, values=c("#CCCCCC", "#999999", "#666666")) +
#   geom_bar(stat="identity", position="dodge") +
#   scale_y_continuous(breaks=c(0.0, 0.5, 1.0), limits=c(0,1)) +
#   xlab("") +
#   ylab("") +
#   theme_classic() +
#   theme(legend.position="none")
# })
# #Make a list of barplots with odds > 1
# plots_2 <- lapply(plot_results_2$Proclivity %>% unique(), function(x){
#   ggplot(plot_results_2 %>% filter(Proclivity == x), aes(x=class, y=odds, fill=as.factor(class))) +
#   scale_fill_manual(name=NULL, values=c("#CCCCCC", "#999999", "#666666")) +
#   geom_bar(stat="identity", position="dodge") +
#   xlab("") +
#   ylab("") +
#   theme_classic() +
#   theme(legend.position="none")
#   })
# #Manually add scale labels to the "outer" plots
# plots[[1]] <- plots[[1]] + ylab("Odds")
# plots[[7]] <- plots[[7]] + ylab("Odds")
# plots[[1]] <- plots[[1]] + ylab("Odds")
# plots[[7]] <- plots[[7]] + ylab("Odds")
# plots[[12]] <- plots[[12]] + xlab("Class")
# plots[[13]] <- plots[[13]] + xlab("Class") + ylab("Odds")
# plots[[14]] <- plots[[14]] + xlab("Class")
# plots_2[[1]] <- plots_2[[1]] + xlab("Class")
# plots_2[[2]] <- plots_2[[2]] + xlab("Class")
# plots_2[[3]] <- plots_2[[3]] + xlab("Class")
# #Arrange all barplots in a grid
# ggarrange(plotlist=c(plots, plots_2), ncol=6, nrow=3)
#Load precoded functions
source("./functions/D_matrix_modal.R")
source("./functions/modal_weights.R")
#Creating a dataframe with modal weights
#First, extract posterior probabilities for class assignment and most likely class membership
posteriors_f <- class_prob(lca_final_model_f, type="individual")$individual %>% as_tibble()
#Compute the inverse D matrix as in Bakk et al. (2013)
inverse_D_f <- solve(D_matrix_modal(posteriors_f))
#Extract a vector with the most likely class memberships
modal_assignments_f <- posteriors_f %>% select(predicted)
#Use the modal_weights function to create modal weights from the inverse_D matrix and combine the results in a tibble with the posterior probabilities of class membership and the most likely class membership.
BCH_expanded_dataframe_f <- tibble(posteriors_f, modal_weights(modal_assignments_f, inverse_D_f) %>% as_tibble())
colnames(BCH_expanded_dataframe_f) <- c("postprob_class_1", "postprob_class_2", "postprob_class_3", "modal_class", "modal_weight_1", "modal_weight_2", "modal_weight_3")
#Clean up
rm(modal_assignments_f, inverse_D_f, posteriors_f)
#Attach the CASE variable to our weighted dataframe.
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(CASE = data_females$CASE)
#We convert the expanded data frame from wide in long format, so that we can use it as an input for our further analyses. According to Bakk et al. (2016), each participant enters the analysis nclass times, each time differently weighted according to her class assignment.
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% pivot_longer(cols=starts_with("modal_weight"), values_to = "modal_weight", names_to=NULL)
#Create a variable that encodes the assumed class assignments for the BCH analysis
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(predicted_class = vctrs::vec_rep(1:3, nrow(data_females)))
#Create dummy variables from this variable
BCH_expanded_dataframe_f <- fastDummies::dummy_cols(BCH_expanded_dataframe_f, select_columns = "predicted_class")
#Combine the expanded dataframe with the outcome variables
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% full_join(y=haven::read_spss("./data/data raw/dataE_clear5 2209.sav") %>% filter(gender == 1) %>% select(CASE, starts_with("Y_") & ends_with("r")) %>% mutate(CASE = CASE %>% as.numeric()), by="CASE")
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_2 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0, .default = BCH_expanded_dataframe_f$modal_weight))
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_3 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0.01, .default = BCH_expanded_dataframe_f$modal_weight))
outcomes_f <- BCH_expanded_dataframe_f %>% select(starts_with("Y_")) %>% colnames()
predictors_f <- BCH_expanded_dataframe_f %>% select(starts_with("predicted")) %>% select(-predicted_class, -predicted_class_3) %>% colnames() %>% paste(collapse=" + ")
models_f <- paste(outcomes_f, "~", predictors_f, sep=" ")
log_regs_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_2) %>% flic()
log_regs_f <- list()
for (i in 1:17){
log_regs_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_2) %>% flic()
}
log_regs_min_f <- list()
for (i in 1:17){
log_regs_min_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, control = logistf.control(fit="IRLS"), model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_3) %>% flic()
}
#Because of the case weights we have to test the parameters manually via likelihood ratio tests
BCH_results_f <- BCH_results_f %>% mutate(
lr_1 = lapply(BCH_results_f$models, logistftest, test=1,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_2 = lapply(BCH_results_f$models, logistftest, test=2,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_3 = lapply(BCH_results_f$models, logistftest, test=3,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_total = lapply(BCH_results_f$models, logistftest, weights=BCH_expanded_dataframe_f$modal_weight_2))
#Combine the results in a dataframe
BCH_results_f <- BCH_results_f %>% mutate(models = log_regs_f)
#Set up a dataframe for the the outputs of the regression analysis. Each row corresponds to one item.
BCH_results_f <- tibble(outcomes = c(colnames(BCH_expanded_dataframe_f %>% select(starts_with("Y_")))))
#Combine the results in a dataframe
BCH_results_f <- BCH_results_f %>% mutate(models = log_regs_f)
BCH_results_f <- BCH_results_f %>% mutate(models_0.01_weights = log_regs_min_f)
#Because of the case weights we have to test the parameters manually via likelihood ratio tests
BCH_results_f <- BCH_results_f %>% mutate(
lr_1 = lapply(BCH_results_f$models, logistftest, test=1,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_2 = lapply(BCH_results_f$models, logistftest, test=2,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_3 = lapply(BCH_results_f$models, logistftest, test=3,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_total = lapply(BCH_results_f$models, logistftest, weights=BCH_expanded_dataframe_f$modal_weight_2))
#Load precoded functions
source("./functions/D_matrix_modal.R")
source("./functions/modal_weights.R")
#Creating a dataframe with modal weights
#First, extract posterior probabilities for class assignment and most likely class membership
posteriors_f <- class_prob(lca_final_model_f, type="individual")$individual %>% as_tibble()
#Do not show code chunks in the knitted document
knitr::opts_chunk$set(echo=F, warning=F, message=F)
#For reproducible results
set.seed(100)
#Turn off scientific notification
options(scipen=999)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM", "MOTE", "flextable", "logistf")
#Load function to check whether required packages are installed & load required packages
source("./functions/check_required_packages.R")
check_required_packages(packages)
lapply(packages, require, character.only=T)
#Clean up
rm(packages)
#######ATTENTION!!!
#At this point we load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=F specifications in all code blocks will make that possible
load(".RData")
##DATA##
#We use gender instead of sex. A 1 represents a female. We want to only grab females.
data_females <- haven::read_spss("./data/data raw/dataE_2112.sav") %>% dplyr::select(gender, CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% filter(gender == 1) %>% dplyr::select(-gender)
#Load precoded functions
source("./functions/D_matrix_modal.R")
source("./functions/modal_weights.R")
#Creating a dataframe with modal weights
#First, extract posterior probabilities for class assignment and most likely class membership
posteriors_f <- class_prob(lca_final_model_f, type="individual")$individual %>% as_tibble()
#Compute the inverse D matrix as in Bakk et al. (2013)
inverse_D_f <- solve(D_matrix_modal(posteriors_f))
#Extract a vector with the most likely class memberships
modal_assignments_f <- posteriors_f %>% select(predicted)
#Use the modal_weights function to create modal weights from the inverse_D matrix and combine the results in a tibble with the posterior probabilities of class membership and the most likely class membership.
BCH_expanded_dataframe_f <- tibble(posteriors_f, modal_weights(modal_assignments_f, inverse_D_f) %>% as_tibble())
colnames(BCH_expanded_dataframe_f) <- c("postprob_class_1", "postprob_class_2", "postprob_class_3", "modal_class", "modal_weight_1", "modal_weight_2", "modal_weight_3")
#Clean up
rm(modal_assignments_f, inverse_D_f, posteriors_f)
#Attach the CASE variable to our weighted dataframe.
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(CASE = data_females$CASE)
#We convert the expanded data frame from wide in long format, so that we can use it as an input for our further analyses. According to Bakk et al. (2016), each participant enters the analysis nclass times, each time differently weighted according to her class assignment.
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% pivot_longer(cols=starts_with("modal_weight"), values_to = "modal_weight", names_to=NULL)
#Create a variable that encodes the assumed class assignments for the BCH analysis
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(predicted_class = vctrs::vec_rep(1:3, nrow(data_females)))
#Create dummy variables from this variable
BCH_expanded_dataframe_f <- fastDummies::dummy_cols(BCH_expanded_dataframe_f, select_columns = "predicted_class")
#Combine the expanded dataframe with the outcome variables
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% full_join(y=haven::read_spss("./data/data raw/dataE_clear5 2209.sav") %>% filter(gender == 1) %>% select(CASE, starts_with("Y_") & ends_with("r")) %>% mutate(CASE = CASE %>% as.numeric()), by="CASE")
#The Regression estimation appears to be not working with negative weights. I do not understand why this is neccessarily the case. We approach to ad-hoc solutions: 1. Fixing the negative weights to zero, 2. We fix the negative weights to 0.01.
#Fixing negative weights to zero or nigh-zero
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_2 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0, .default = BCH_expanded_dataframe_f$modal_weight))
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_3 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0.01, .default = BCH_expanded_dataframe_f$modal_weight))
#We prepare the model specifications for the Firth Regression to run.
outcomes_f <- BCH_expanded_dataframe_f %>% select(starts_with("Y_")) %>% colnames()
predictors_f <- BCH_expanded_dataframe_f %>% select(starts_with("predicted")) %>% select(-predicted_class, -predicted_class_1) %>% colnames() %>% paste(collapse=" + ")
models_f <- paste(outcomes_f, "~", predictors_f, sep=" ")
#Do Flic (Firth's regression with intercept correction) for the models in the list with weights fixed to zero.
log_regs_f <- list()
for (i in 1:17){
log_regs_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_2) %>% flic()
}
##Do Flic for the models in the list with weights fixed to 0.01
log_regs_min_f <- list()
for (i in 1:17){
log_regs_min_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, control = logistf.control(fit="IRLS"), model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_3) %>% flic()
}
#Set up a dataframe for the the outputs of the regression analysis. Each row corresponds to one item.
BCH_results_f <- tibble(outcomes = c(colnames(BCH_expanded_dataframe_f %>% select(starts_with("Y_")))))
#Combine the results in a dataframe
<<<<<<< Updated upstream
BCH_results_f <- BCH_results_f %>% mutate(models = log_regs_f)
BCH_results_f <- BCH_results_f %>% mutate(models_0.01_weights = log_regs_min_f)
#Because of the case weights we have to test the parameters manually via likelihood ratio tests
BCH_results_f <- BCH_results_f %>% mutate(
lr_1 = lapply(BCH_results_f$models, logistftest, test=1,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_2 = lapply(BCH_results_f$models, logistftest, test=2,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_3 = lapply(BCH_results_f$models, logistftest, test=3,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_total = lapply(BCH_results_f$models, logistftest, weights=BCH_expanded_dataframe_f$modal_weight_2, control=logistf.control(maxit=10000))) #We get a warning: Maximum number of iterations for null model exceeded. Neither increasing the maximum number of iterations nor using a different start value (by changing the seed) help.
BCH_results_f <- BCH_results_f %>% mutate(
lr_1_0.01 = lapply(BCH_results_f$models, logistftest, test=1,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")),
lr_2_0.01 = lapply(BCH_results_f$models, logistftest, test=2,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")),
lr_3_0.01 = lapply(BCH_results_f$models, logistftest, test=3,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")),
lr_total_0.01 = lapply(BCH_results_f$models, logistftest,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")))
#We extract p-values from the likelihood ratio tests.
BCH_results_f <- BCH_results_f %>% mutate(
p_1=lapply(BCH_results_f$lr_1, function(x){x$prob}) %>% unlist(),
p_2=lapply(BCH_results_f$lr_2, function(x){x$prob}) %>% unlist(),
p_3=lapply(BCH_results_f$lr_3, function(x){x$prob}) %>% unlist(),
p_1_0.01=lapply(BCH_results_f$lr_1_0.01, function(x){x$prob}) %>% unlist(),
p_2_0.01=lapply(BCH_results_f$lr_2_0.01, function(x){x$prob}) %>% unlist(),
p_3_0.01=lapply(BCH_results_f$lr_3_0.01, function(x){x$prob}) %>% unlist(),
)
#Order BCH_results
BCH_results_f <- BCH_results_f[order(BCH_results_f$outcomes),]
#Add parameter estimates
#How to index the results_parameters table:
#All regression weights start with "b",
#All model output from the 0.01 weighted regression ends with "_0.01"
#All lower confidence interval limits begin with ci_l
#All upper confidence interval limits begin with ci_r
#All lr-test p-values start with p_lr
#Use tidyverse select functions
BCH_results_parameters_f <- tibble(outcomes = BCH_results_f$outcomes,
b_intercept = lapply(BCH_results_f$models, function(x){x$coefficients[1]}) %>% unlist(),
b_predicted_class_2 = lapply(BCH_results_f$models, function(x){x$coefficients[2]}) %>% unlist(),
b_predicted_class_3 =lapply(BCH_results_f$models, function(x){x$coefficients[3]}) %>% unlist(),
b_intercept_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[1]}) %>%
unlist(),
b_predicted_class_2_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[2]}) %>%
unlist(),
b_predicted_class_3_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[3]}) %>%
unlist(),
ci_l_intercept = lapply(BCH_results_f$models, function(x){x$ci.lower[1]}) %>% unlist(),
ci_l_predicted_class_2 =lapply(BCH_results_f$models, function(x){x$ci.lower[2]}) %>% unlist(),
ci_l_predicted_class_3 =lapply(BCH_results_f$models, function(x){x$ci.lower[3]}) %>% unlist(),
ci_l_intercept_0.01= lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[1]}) %>% unlist(),
ci_l_predicted_class_2_0.01=lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[2]}) %>%
unlist(),
ci_l_predicted_class_3_0.01=lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[3]}) %>%
unlist(),
ci_r_intercept =lapply(BCH_results_f$models, function(x){x$ci.upper[1]}) %>% unlist(),
ci_r_predicted_class_2=lapply(BCH_results_f$models, function(x){x$ci.upper[2]}) %>% unlist(),
ci_r_predicted_class_3=lapply(BCH_results_f$models, function(x){x$ci.upper[3]}) %>% unlist(),
ci_r_intercept_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[1]}) %>% unlist(),
ci_r_predicted_class_2_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[2]}) %>%
unlist(),
ci_r_predicted_class_3_0.01  = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[3]}) %>%
unlist(),
p_lr_intercept = lapply(BCH_results_f$lr_1, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_2 = lapply(BCH_results_f$lr_2, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_3 = lapply(BCH_results_f$lr_3, function(x){x$prob}) %>% unlist(),
p_lr_intercept_0.01 = lapply(BCH_results_f$lr_1_0.01, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_2_0.01 = lapply(BCH_results_f$lr_2_0.01, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_3_0.01 = lapply(BCH_results_f$lr_3_0.01, function(x){x$prob}) %>% unlist(),
p_lr_total = lapply(BCH_results_f$lr_total, function(x){x$prob}) %>% unlist(),
p_lr_total_0.01 = lapply(BCH_results_f$lr_total_0.01, function(x){x$prob}) %>% unlist())
# #Save output to RDS.
# BCH_results_f %>% saveRDS(file="./out/BCH_results_f.RDS")
#
# #Save Parameters Table to RDS
BCH_results_parameters_f %>% saveRDS(file="./out/BCH_results_parameters_f.RDS")
save.image("C:/Users/Rebecca/Documents/GitHub/LPA_analysis/.RData")
flextable(class_prob_lca_f) %>%
theme_booktabs()
#Do not show code chunks in the knitted document
knitr::opts_chunk$set(echo=F, warning=F, message=F)
#For reproducible results
set.seed(100)
#Turn off scientific notification
options(scipen=999)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM", "MOTE", "flextable", "logistf")
#Load function to check whether required packages are installed & load required packages
source("./functions/check_required_packages.R")
check_required_packages(packages)
lapply(packages, require, character.only=T)
#Clean up
rm(packages)
#######ATTENTION!!!
#At this point we load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=F specifications in all code blocks will make that possible
load(".RData")
##DATA##
#We use gender instead of sex. A 1 represents a female. We want to only grab females.
data_females <- haven::read_spss("./data/data raw/dataE_2112.sav") %>% dplyr::select(gender, CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% filter(gender == 1) %>% dplyr::select(-gender)
flextable(class_prob_lca_f) %>%
theme_booktabs()
flextable(as.data.frame(class_prob_lca_f)) %>%
theme_booktabs()
as.data.frame(class_prob_lca_f)
flextable(lca_fit_f) %>%
set_formatter(Entropy=function(x) format(round(x, 2), nsmall=2),
prob_min=function(x) format(round(x, 2), nsmall=2),
prob_max=function(x) format(round(x, 2), nsmall=2),
n_min=function(x) format(round(x, 2), nsmall=2),
np_ratio=function(x) format(round(x, 2), nsmall=2),
np_local=function(x) format(round(x, 2), nsmall=2)) %>%
set_header_labels(Name="Number of classes", LL="LogLikelihood", n="N", prob_min="Min prob", prob_max="Max prob", n_min="Min n", np_ratio="NP ratio", np_local="Local NP") %>%
theme_booktabs() %>%
autofit()
lca_fit_f
#Do not show code chunks in the knitted document
knitr::opts_chunk$set(echo=F, warning=F, message=F)
#For reproducible results
set.seed(100)
#Turn off scientific notification
options(scipen=999)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM", "MOTE", "flextable", "logistf")
#Load function to check whether required packages are installed & load required packages
source("./functions/check_required_packages.R")
check_required_packages(packages)
lapply(packages, require, character.only=T)
#Clean up
rm(packages)
#######ATTENTION!!!
#At this point we load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=F specifications in all code blocks will make that possible
load(".RData")
##DATA##
#We use gender instead of sex. A 1 represents a female. We want to only grab females.
data_females <- haven::read_spss("./data/data raw/dataE_2112.sav") %>% dplyr::select(gender, CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% filter(gender == 1) %>% dplyr::select(-gender)
View(lca_fit_f)
lca_fit_f <- table_fit(lca_models_f) %>% select(Name, LL, n, Parameters, BIC, Entropy, prob_min, prob_max, n_min, np_ratio, np_local)
save.image("C:/Users/Rebecca/Documents/GitHub/LPA_analysis/.RData")
flextable(lca_fit_f) %>%
set_formatter(Entropy=function(x) format(round(x, 2), nsmall=2),
prob_min=function(x) format(round(x, 2), nsmall=2),
prob_max=function(x) format(round(x, 2), nsmall=2),
n_min=function(x) format(round(x, 2), nsmall=2),
np_ratio=function(x) format(round(x, 2), nsmall=2),
np_local=function(x) format(round(x, 2), nsmall=2)) %>%
set_header_labels(Name="Number of classes", LL="LogLikelihood", n="N", prob_min="Min prob", prob_max="Max prob", n_min="Min n", np_ratio="NP ratio", np_local="Local NP") %>%
theme_booktabs() %>%
autofit()
plot_prob(lca_final_model_f) +
scale_fill_grey(start = 0.9, end = 0.5, aesthetics = "fill") +
scale_x_discrete(labels=c("attr"="Attraction to children", "CSBD"="Compulsive sex.", "lon"="Loneliness", "meffort"="Mating effort", "mvalue"="Mate value", "PPCS_6"="Probl. porn use", "sexdrive2"="Sex drive", "socialanx"="Social anxiety")) +
labs(x="") +
theme_classic() +
theme(axis.text.x=element_text(angle=65, hjust=1, size=10))
=======
BCH_results <- BCH_results %>% mutate(models = log_regs)
BCH_results <- BCH_results %>% mutate(models_0.01_weights = log_regs_min)
View(BCH_results)
lca_models_f %>% class()
lca_models_m %>% class()
test <- as(lca_models_m, "mixture_list")
lr_lmr(lca_final_model_m)
lr_lmr(lca_final_model_m, lca_models_m[[2]])
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
library(tidyverse)
library(logistf)
View(BCH_results)
>>>>>>> Stashed changes
