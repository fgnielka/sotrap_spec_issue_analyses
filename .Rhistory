<<<<<<< Updated upstream
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity", position="stack") +
scale_fill_manual(values = c("og_posts" = "black", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
labs(x='week online', y='number of posts') +
theme_classic()
date_dat <- dat %>% group_by(week = week(post_time_datetime)) %>% summarise(og_posts = sum(post_original==1), re_posts = sum(post_original==0), users = length(unique(member_id)))
View(date_dat)
date_dat$week <- c(1:25)
date_dat <- pivot_longer(date_dat, cols=c(og_posts, re_posts), values_to="no_posts")
colnames(date_dat)[3] <- "post_type"
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity", position="stack") +
scale_fill_manual(values = c("og_posts" = "black", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "black", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=users)) +
geom_bar(stat="identity") +
labs(x='week online', y='number of users') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "black", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes=users) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "black", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
scale_colour_manual(values='black', name=NULL, labels='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
scale_colour_manual(values='black', name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
scale_linetype_discrete(values='solid', name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
colour_manual
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
scale_colour_manual(values='black', name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, colour=users)) +
scale_colour_manual(values='black', name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, colour=users)) +
scale_colour_discrete(values='black', name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, colour=users)) +
scale_colour_discrete(values=c('users'='black'), name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, colour=users)) +
scale_colour_discrete(values=c('black'), name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, colour=users)) +
scale_colour_manual(values=c('black'), name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
scale_colour_manual(values=c('black'), name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users), linetype="solid") +
scale_linetype_manual(values='solid', name=NULL, label='users') +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users), linetype="users") +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users), linetype=users) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, linetype=users)) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, linetype=users)) +
scale_linetype_manual(values=c('users'="black")) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, linetype=users)) +
scale_linetype_discrete(values=c('users'="black")) +
labs(x='week online', y='number of posts') +
theme_classic()
?scale_linetype_discrete
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users, linetype=users)) +
scale_linetype_discrete(values=c('users'="solid")) +
labs(x='week online', y='number of posts') +
theme_classic()
ggplot(date_dat, aes(x=week, y=no_posts, fill=factor(post_type, levels=c('re_posts', 'og_posts')))) +
geom_bar(stat="identity") +
scale_fill_manual(values = c("og_posts" = "darkgrey", "re_posts" = "lightgrey"), name=NULL, labels=c('original posts', 'replies')) +
geom_line(aes(y=users)) +
labs(x='week online', y='number of posts') +
theme_classic()
library(rio)
=======
set.seed(42)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "psych")
#load function to check whether required packages are installed.
source("./functions/check_required_packages.R")
check_required_packages(packages)
#load required packages
lapply(packages, require, character.only=T)
data <- haven::read_spss("./data/data raw/dataE_clear5 2209.sav") %>% select(CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr)
data <- haven::read_spss("./data/data_raw/dataE_clear5 2209.sav") %>% select(CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr)
View(data)
data <- haven::read_spss("./data/data_raw/dataE_clear5 2209.sav")
View(data)
colnames(data) %>% grep("y")
colnames(data) %>% grep("Y")
?starts_with()
data %>% select(starts_with("Y"))
data %>% select(starts_with("Y")) %>% colnames()
data %>% select(starts_with("Y")) %>% select(ends_with("r")) %>% head()
View(data)
data %>% select(CASE, starts_with("Y")) %>% select(CASE, ends_with("r")) %>% head()
data %>% select(CASE, starts_with("Y")) %>% select(CASE, ends_with("r")) %>% colnames()
data <- haven::read_spss("./data/data_raw/dataE_clear5 2209.sav") %>% select(CASE, starts_with("Y")) %>% select(CASE, ends_with("r"))
View(data)
?psych::fa()
tetrachoric(data %>% select(-CASE)) %>% psych::scree()
polychoric(data %>% select(-CASE)) %>% psych::scree()
polychoric(data %>% select(-CASE))
polychoric(data %>% select(-CASE)) %>% view()
polychoric(data %>% select(-CASE)) %>% as.matrix()
corr <- polychoric(data %>% select(-CASE)) %>% as.matrix()
View(corr)
corr <- polychoric(data %>% select(-CASE))
corr$rho
corr <- corr$rho
corr %>% class()
corr <- polychoric(data %>% select(-CASE))$rho
scree(polychoric(data %>% select(-CASE))$rho)
?psych::fa
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax")
install.packages("GPArotation")
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax")
summary(efa_3)
efa_3
print(efa_3, cut=.4, sort = T, digits=2)
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax", fm="old.min")
efa_3 <- psych::fa(corr, nfactors=3, rotation="promax", fm="old.min", data=data %>% select(-CASE))
install.packages("jaspFactor")
efa_2 <- psych::fa(corr, nfactors=2, rotation="promax", fm="")
efa_2 <- psych::fa(corr, nfactors=2, rotation="promax")
load("C:/ARICA/WP3 RAs/Frederic/General_Assembly_2024/Relational_Analysis/.Rhistory")
save.image("C:/ARICA/WP3 RAs/Frederic/General_Assembly_2024/Relational_Analysis/.RData")
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "igraph")
#load required packages
lapply(packages, require, character.only=T)
#Define a function that takes the dataframe with topic_ids and vectors with member_ids of posters and returns a list of tibbles in which each unique possible combination of posters is reported in a combinations column.
get_unique_poster_tuples <- function(row, dataframe, column_of_poster_ids, column_of_topic_ids){
poster_vector <- dataframe %>% pull(column_of_poster_ids)
poster_vector <- poster_vector[[row]]
poster_dataframe <- expand_grid(names_1= poster_vector, names_2 = poster_vector) %>%
mutate(names_1 = as.numeric(names_1),
names_2 = as.numeric(names_2))
poster_dataframe <-  poster_dataframe %>%
mutate(combinations = lapply( 1:nrow(poster_dataframe),                                                                      function(x){c(poster_dataframe$names_1[x],poster_dataframe$names_2[x]) %>% sort()})) %>%
filter(names_1 != names_2) %>%
distinct(combinations, .keep_all = TRUE)
topic_id <- dataframe %>% pull(column_of_topic_ids)
topic_id <- rep(topic_id[[row]], times=nrow(poster_dataframe))
poster_dataframe <- poster_dataframe %>% mutate(topic_id = topic_id)
return(poster_dataframe)
}
#Enter the list of tibbles to our topic_network tibble.
posters_in_topic <- lapply(1:nrow(topic_network), get_unique_poster_tuples, dataframe=topic_network, column_of_poster_ids = "posters", column_of_topic_ids = "topic_id")
#We load the required data from the phpbb_total.sav file in the pedleaks folder.
cols <- c("post_id", "member_id", "topic_id", "forum_id", "post_original", "post_reply", "post_time")
data <- haven::read_spss("./data/phpbb_posts nested within members.sav") %>% select(all_of(cols))
"C:\ARICA\WP3 RAs\Frederic\General_Assembly_2024\Relational_Analysis\data\phpbb_posts nested within members.sav"
#We load the required data from the phpbb_total.sav file in the pedleaks folder.
cols <- c("post_id", "member_id", "topic_id", "forum_id", "post_original", "post_reply", "post_time")
data <- haven::read_spss("./data/phpbb_posts nested within members.sav") %>% select(all_of(cols))
topic_network <- data %>% as_tibble()%>% group_by(topic_id) %>% summarize(posters = stringr::str_c(member_id, collapse=",")) %>% mutate(posters = str_split(posters, pattern=","))
#Define a function that takes the dataframe with topic_ids and vectors with member_ids of posters and returns a list of tibbles in which each unique possible combination of posters is reported in a combinations column.
get_unique_poster_tuples <- function(row, dataframe, column_of_poster_ids, column_of_topic_ids){
poster_vector <- dataframe %>% pull(column_of_poster_ids)
poster_vector <- poster_vector[[row]]
poster_dataframe <- expand_grid(names_1= poster_vector, names_2 = poster_vector) %>%
mutate(names_1 = as.numeric(names_1),
names_2 = as.numeric(names_2))
poster_dataframe <-  poster_dataframe %>%
mutate(combinations = lapply( 1:nrow(poster_dataframe),                                                                      function(x){c(poster_dataframe$names_1[x],poster_dataframe$names_2[x]) %>% sort()})) %>%
filter(names_1 != names_2) %>%
distinct(combinations, .keep_all = TRUE)
topic_id <- dataframe %>% pull(column_of_topic_ids)
topic_id <- rep(topic_id[[row]], times=nrow(poster_dataframe))
poster_dataframe <- poster_dataframe %>% mutate(topic_id = topic_id)
return(poster_dataframe)
}
#Enter the list of tibbles to our topic_network tibble.
posters_in_topic <- lapply(1:nrow(topic_network), get_unique_poster_tuples, dataframe=topic_network, column_of_poster_ids = "posters", column_of_topic_ids = "topic_id")
topic_network <- topic_network %>% mutate(posters_in_topic = posters_in_topic)
#Enter a column with the number of posters in every topic
topic_network <- topic_network %>% mutate(n_posters = topic_network$posters %>% lapply(length))
rm(posters_in_topic)
#Filter out all values in which only one person has posted in the topic. In a network they would end up being dots without connections. We save them in a serperate tibble however, if one wishes to analyse them later on.
topic_network_unanswered_topics <- topic_network %>% filter(n_posters <  2)
topic_network_answered_topics <- topic_network %>% filter(n_posters > 1)
#We remove the topic_network tibble. We can always recreate it by combining the topic_network_answered_topics and topic_network_unanswered_topics tibbles.
rm(topic_network)
#We combine the tibbles of unique combinations of posters in all topics by column.
test <- map_dfr(topic_network_answered_topics$posters_in_topic, bind_rows)
#We now have a table that tells us who posts together in a topic. However we do not yet know who DOESN'T post together.
# To DO: Look up how an edge lists object has to look like in igraph. Find a way to add all posters who engage in threads with more than one post together and create a dummy variable with people who post together in one topic and people who do not post together in a topic. Maybe consider using group_by name_1 or something and sum to create a weighed edge list.
test_summary <- test %>% group_by(combinations) %>% reframe(combinations = combinations,topic_id = topic_id, n = n())
name_1 <- lapply(1:nrow(test_summary), function(x){test_summary$combinations[[x]][1]}) %>% flatten() %>% unlist()
name_2 <- lapply(1:nrow(test_summary), function(x){test_summary$combinations[[x]][2]}) %>% flatten() %>% unlist()
test_summary <- test_summary %>%  mutate(names_1 = name_1, names_2 = name_2)
test_summary <- test_summary %>% group_by(combinations) %>% reframe(topic_ids = paste(topic_id, collapse=","), n=n, names_1 = names_1, names_2 = names_2) %>% distinct()
test_summary <- test_summary %>% mutate(topic_ids = lapply(1:nrow(test_summary), function(x){test_summary$topic_ids[[x]] %>% str_split_1(",") %>% as.numeric()}))
#We combine the tibbles of unique combinations of posters in all topics by column.
topic_network_edges <- map_dfr(topic_network_answered_topics$posters_in_topic, bind_rows)
#We now have a table that tells us who posts together in a topic. However we do not yet know who DOESN'T post together.
# To DO: Look up how an edge lists object has to look like in igraph. Find a way to add all posters who engage in threads with more than one post together and create a dummy variable with people who post together in one topic and people who do not post together in a topic. Maybe consider using group_by name_1 or something and sum to create a weighed edge list.
topic_network_edges <- topic_network_edges %>% group_by(combinations) %>% reframe(combinations = combinations,topic_id = topic_id, n = n())
name_1 <- lapply(1:nrow(topic_network_edges), function(x){topic_network_edges$combinations[[x]][1]}) %>% flatten() %>% unlist()
name_2 <- lapply(1:nrow(topic_network_edges), function(x){topic_network_edges$combinations[[x]][2]}) %>% flatten() %>% unlist()
topic_network_edges <- topic_network_edges %>%  mutate(names_1 = name_1, names_2 = name_2)
topic_network_edges <- topic_network_edges %>% group_by(combinations) %>% reframe(topic_ids = paste(topic_id, collapse=","), n=n, names_1 = names_1, names_2 = names_2) %>% distinct()
topic_network_edges <- topic_network_edges %>% mutate(topic_ids = lapply(1:nrow(topic_network_edges), function(x){topic_network_edges$topic_ids[[x]] %>% str_split_1(",") %>% as.numeric()}))
#topic_network_edges is the output of our data wrangling. It includes a weighted undirected edgelist, that who posted in the same topics in pedoleaks (nodes = names_1, names_2; edge_weights = n). We know which topics these were, because a vector for each unique combination of users, who posted in the same topic, the ids of the common topics saved in the column "topic_ids".
rm(test, test_summary, efa_3, corr)
View(topic_network_edges)
topic_network <- list("answered_topics" = topic_network_answered_topics, "unanswered_topics" =topic_network_unanswered_topics, "edges_at" = topic_network_edges)
rm(topic_network_answered_topics, topic_network_edges, topic_network_unanswered_topics)
topic_network[["edges_at"]]
g <- graph_from_data_frame(topic_network[["edges_at"]] %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
View(g)
print(g, e=TRUE, v=TRUE)
g <- graph_from_data_frame(topic_network[["edges_at"]] %>% select(names_1, names_1, n) %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
g <- graph_from_data_frame(topic_network[["edges_at"]] %>% select(names_1, names_2, n) %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
print(g, e=TRUE, v=TRUE)
attr(g, "weight")
attributes(g)
E(g)
topic_network[["edges_at"]] %>% pull(n)
E(g)$weight <- topic_network[["edges_at"]] %>% pull(n)
print(g, e=TRUE, v=TRUE)
is_weighted(g)
vertex_connectivity(g)
degree(g, v=V(g))
degree(g, v=V(g)) %>% view()
topic_graph <- graph_from_data_frame(topic_network[["edges_at"]] %>% select(names_1, names_2, n) %>% rename(Source = names_1, Target = names_2, weight = n), directed=FALSE)
E(topic_graph)$weight <- topic_network[["edges_at"]] %>% pull(n)
print(g, e=TRUE, v=TRUE)
View(topic_network)
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph)) %>% as.tibble() %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph)) %>% as_tibble() %>% rownames_to_column("user_id")
View(centrality_topic_graph)
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph)) %>% as.tibble() %>% rename(degree = value) %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))  %>% rename(degree = value) %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))  %>% rownames_to_column("user_id")
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))
centrality_topic_graph %>% class()
rownames(centrality_topic_graph)
centrality_topic_graph <- degree(topic_graph, v=V(topic_graph))
centrality_topic_graph %>% rownames()
centrality_topic_graph %>% attributes()
centrality_topic_graph %>% names()
degree(topic_graph, v=V(topic_graph))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph))$names, "degree" = degree(topic_graph, v=V(topic_graph)))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph)))
View(centrality_topic_graph)
degree(topic_graph, v=V(topic_graph), normalized=T)
betweenness(topic_graph)
strength(topic_graph)
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph))) %>% mutate(degree_centralized = degree(topic_graph, v=V(topic_graph), centralized=T), weigthed_degree = strength(topic_graph), weighted_degree_centralized = strength(topic_graph, centralized=T))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph))) %>% mutate(degree_normalized = degree(topic_graph, v=V(topic_graph), normalized = T), weigthed_degree = strength(topic_graph), weighted_degree_normalized = strength(topic_graph, normalized=T))
centrality_topic_graph <- tibble("user_id" = degree(topic_graph, v=V(topic_graph)) %>% names(), "degree" = degree(topic_graph, v=V(topic_graph))) %>% mutate(degree_normalized = degree(topic_graph, v=V(topic_graph), normalized = T), weigthed_degree = strength(topic_graph))
vertex_connectivity(topic_graph)
View(centrality_topic_graph)
load("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/LCA_analysis.Rmd")
load("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM")
#load function to check whether required packages are installed.
source("./functions/check_required_packages.R")
check_required_packages(packages)
#load required packages
lapply(packages, require, character.only=T)
#######ATTENTION:
#At this point I load a presaved RData variables in which the  environment is saved. That makes the code less reproduceable, but removing the eval=FALSE specifications in all code blocks will make that possible.
load(".RData")
options(scipen = 999)
View(prob_table_LCA_m)
prob_table_LCA_m <- reshape(prob_table_LCA_m, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
View(prob_table_LCA_m)
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category")) %>% view()
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
prob_table_LCA_f <- table_prob(lca_final_model_f)
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
View(data)
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
install.packages("foreign")
prob(lca_final_model_m, type="individual")
>>>>>>> Stashed changes
library(tidyverse)
dat <- import("C:/Users/Rebecca/Folders/MSB/Projekte/Special issue/dataE_2112.sav")
plotd <- dat %>% select(CASE, gender, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% pivot_longer(cols=sexdrive2:attr, names_to="var", values_to="score")
source("./flat_violin.R")
plotd %>% select(var=c("sexdrive2", CSBD))
?filter
plotd %>% filter(var==('sexdrive2' | 'CSBD'))
library(rio)
library(tidyverse)
dat <- import("C:/Users/Rebecca/Folders/MSB/Projekte/Special issue/dataE_2112.sav")
plotd <- dat %>% select(CASE, gender, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% pivot_longer(cols=sexdrive2:attr, names_to="var", values_to="score")
source("./flat_violin.R")
ggplot(plotd, aes(x = var, y = score, fill = var)) +
geom_flat_violin(scale = "count", trim=F, width=5) +
#scale_fill_viridis(discrete = TRUE) +
#stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = "pointrange", position = position_nudge(4.9)) +
geom_dotplot(binaxis = "y", dotsize = 0.01, stackdir = "down", binwidth = 0.3, position = position_nudge(-0.025)) +
#theme_ipsum() +
theme(
legend.position = "none"
) +
ylab("value")
?geom_violin
ggplot(plotd, aes(x = var, y = score, fill = var)) +
geom_flat_violin(trim=F, width=5) +
#scale_fill_viridis(discrete = TRUE) +
#stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = "pointrange", position = position_nudge(4.9)) +
geom_dotplot(binaxis = "y", dotsize = 0.01, stackdir = "down", binwidth = 0.3, position = position_nudge(-0.025)) +
#theme_ipsum() +
theme(
legend.position = "none"
) +
ylab("value")
ggplot(plotd, aes(x = var, y = score, fill = var)) +
geom_flat_violin(scale = "width", trim=F, width=5) +
#scale_fill_viridis(discrete = TRUE) +
#stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = "pointrange", position = position_nudge(4.9)) +
geom_dotplot(binaxis = "y", dotsize = 0.01, stackdir = "down", binwidth = 0.3, position = position_nudge(-0.025)) +
#theme_ipsum() +
theme(
legend.position = "none"
) +
ylab("value")
ggplot(plotd, aes(x = var, y = score, fill = var)) +
geom_flat_violin(scale = "width", trim=F) +
#scale_fill_viridis(discrete = TRUE) +
#stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = "pointrange", position = position_nudge(4.9)) +
geom_dotplot(binaxis = "y", dotsize = 0.01, stackdir = "down", binwidth = 0.3, position = position_nudge(-0.025)) +
#theme_ipsum() +
theme(
legend.position = "none"
) +
ylab("value")
plotd %>% select(-attr)
ggplot(plotd %>% filter(var!="attr"), aes(x = var, y = score, fill = var)) +
geom_flat_violin(scale = "width", trim=F) +
#scale_fill_viridis(discrete = TRUE) +
#stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = "pointrange", position = position_nudge(4.9)) +
geom_dotplot(binaxis = "y", dotsize = 0.05, stackdir = "down", binwidth = 0.3, position = position_nudge(-0.025)) +
#theme_ipsum() +
theme(
legend.position = "none"
) +
ylab("value")
ggplot(plotd %>% filter(var!="attr"), aes(x = var, y = score, fill = var)) +
geom_flat_violin(scale = "width", trim=F) +
#scale_fill_viridis(discrete = TRUE) +
#stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = "pointrange", position = position_nudge(4.9)) +
geom_dotplot(binaxis = "y", dotsize = 0.04, stackdir = "down", binwidth = 0.3, position = position_nudge(-0.025)) +
#theme_ipsum() +
theme(
legend.position = "none"
) +
ylab("value")
ggplot(plotd %>% filter(var!="attr"), aes(x = var, y = score, fill = var)) +
geom_flat_violin(scale = "width") +
#scale_fill_viridis(discrete = TRUE) +
#stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = "pointrange", position = position_nudge(4.9)) +
geom_dotplot(binaxis = "y", dotsize = 0.04, stackdir = "down", binwidth = 0.3, position = position_nudge(-0.025)) +
#theme_ipsum() +
theme(
legend.position = "none"
) +
ylab("value")
ggplot(plotd %>% filter(var!="attr"), aes(x=var, y=score, fill=var)) +
geom_flat_violin(scale="width") +
geom_dotplot(binaxis="y", dotsize=.04, stackdir="down", binwidth=.3, position=position_nudge(-.025)) +
theme(legend.position="none") +
labs(x="", y="value") +
ggplot(plotd, aes(x = var, y = score, fill = var)) +
geom_violin(scale = "count")
ggplot(plotd %>% filter(var!="attr"), aes(x=var, y=score, fill=var)) +
geom_flat_violin(scale="width") +
geom_dotplot(binaxis="y", dotsize=.04, stackdir="down", binwidth=.3, position=position_nudge(-.025)) +
theme(legend.position="none") +
labs(x="", y="value")
#plot
ggplot(plotd %>% filter(var!="attr"), aes(x=var, y=score, fill=var)) +
geom_flat_violin(scale="width") +
geom_dotplot(binaxis="y", dotsize=.04, stackdir="down", binwidth=.3, position=position_nudge(-.025)) +
theme(legend.position="none") +
labs(x="", y="value") +
theme_classic()
#plot
ggplot(plotd %>% filter(var!="attr"), aes(x=var, y=score, fill=var)) +
geom_flat_violin(scale="width") +
geom_dotplot(binaxis="y", dotsize=.04, stackdir="down", binwidth=.3, position=position_nudge(-.025)) +
theme_classic() +
theme(legend.position="none") +
labs(x="", y="value")
ggplot(plotd %>% filter(var=="attr"), aes(x=var, y=score)) +
geom_flat_violin(scale="width") +
geom_dotplot(binaxis="y", dotsize=.04, stackdir="down", binwidth=.3, position=position_nudge(-.025)) +
theme_classic() +
theme(legend.position="none") +
labs(x="", y="value")
ggplot(plotd %>% filter(var=="attr"), aes(x=var, y=score)) +
geom_bar()
ggplot(plotd %>% filter(var=="attr"), aes(y=score)) +
geom_bar()
ggplot(plotd %>% filter(var=="attr"), aes(x=score)) +
geom_bar()
ggplot(plotd %>% filter(var=="attr"), aes(x=score)) +
geom_bar() +
theme_classic() +
labs(x="attraction to children", y="count")
x <- rlnorm(1e4, meanlog = -0.5, sdlog = 0.5)
### Class Proportions Females
```{r class_proportion_f, echo=F}
#######ATTENTION:
#At this point I load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=FALSE specifications in all code blocks will make that possible.
load(".RData")
<<<<<<< Updated upstream
desc_m
desc_f
desc_m
desc_m$unique
desc_m$unique-1
desc <- data.frame(Variable=c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children"), Male=desc_m$unique-1, Female=desc_f$unique-1, Male=desc_m$mode, Female=desc_f$mode, Male=desc_m$mode_value, Female=desc_f$mode_value, Male=desc_m$V, Female=desc_f$V)
desc <- data.frame(Male=desc_m$unique-1, Female=desc_f$unique-1, Male=desc_m$mode, Female=desc_f$mode, Male=desc_m$mode_value, Female=desc_f$mode_value, Male=desc_m$V, Female=desc_f$V)
desc <- data.frame("Male"=desc_m$unique-1, "Female"=desc_f$unique-1, "Male"=desc_m$mode, "Female"=desc_f$mode, "Male"=desc_m$mode_value, "Female"=desc_f$mode_value, "Male"=desc_m$V, "Female"=desc_f$V)
desc_m$unique-1
desc_f$unique-1,
desc_f$unique-1
?data.frame
desc <- data.frame("Male"=desc_m$unique-1, "Female"=desc_f$unique-1)
View(desc)
desc <- data.frame(Variable=c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children"), "Male"=desc_m$unique-1, "Female"=desc_f$unique-1)
desc_m$mode
desc_f$mode
desc_m$mode_value
desc <- data.frame(Variable=c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children"), "Male"=desc_m$unique-1, "Female"=desc_f$unique-1, "Male"=desc_m$mode, "Female"=desc_f$mode, "Male"=desc_m$mode_value, "Female"=desc_f$mode_value, "Male"=desc_m$V, "Female"=desc_f$V)
desc <- data.frame(Variable=c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children"), "Male"=desc_m$unique-1, "Female"=desc_f$unique-1, "Male"=desc_m$mode)
desc <- data.frame(Variable=c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children"), "Male"=desc_m$unique-1, "Female"=desc_f$unique-1, "Male"=desc_m$mode, "Female"=desc_f$mode, "Male"=desc_m$mode_value)
desc <- data.frame(Variable=c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children"), "Male"=desc_m$unique-1, "Female"=desc_f$unique-1, "Male"=desc_m$mode, "Female"=desc_f$mode, "Male"=desc_m$mode_value, "Female"=desc_f$mode_value, "Male"=desc_m$v, "Female"=desc_f$v)
View(desc)
desc_f
?full_join
desc <- full_join(desc_m, desc_f, by=0)
library(tidyverse)
desc <- full_join(desc_m, desc_f, by=0)
desc <- merge(desc_m, desc_f, by=0)
desc
desc <- full_join(desc_m, desc_f, by=name)
desc <- merge(desc_m, desc_f, by=name)
desc <- merge(desc_m, desc_f, by="name")
desc
desc <- desc[, sort(names(desc))]
desc
desc <- desc[, sort(names(desc[, 2:15]))]
desc <- merge(desc_m, desc_f, by="name")
desc <- desc[, sort(names(desc[, 2:15]))]
desc
desc <- desc[, 2:15] %>% sort(names(desc))
desc <- merge(desc_m, desc_f, by="name")
desc <- desc[, 2:15] %>% sort(names(desc))
desc <- desc[, sort(names(desc)[2:15])]
desc <- merge(desc_m, desc_f, by="name")
desc <- desc[, sort(names(desc)[2:15])]
desc
desc <- desc[, sort(names(desc))[2:15]]
desc <- merge(desc_m, desc_f, by="name")
desc <- desc[, sort(names(desc))[2:15]]
desc
desc <- merge(desc_m, desc_f, by="name")
desc <- desc[, sort(names(desc))][2:15]
desc
desc <- merge(desc_m, desc_f, by="name")
desc <- cbind(c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children"), desc[, sort(names(desc))])
desc
Variable <- c("Sex drive", "CSBD-7", "PPCS-6", "Mating effort", "Social anxiety", "LON", "Low embodied capital", "Sexual interest in children")
desc <- merge(desc_m, desc_f, by="name")
desc <- cbind(Variable, desc[, sort(names(desc))])
desc
desc <- merge(desc_m, desc_f, by="name")
desc
Variable <- c("Sexual interest in children", "CSBD-7", "LON", "Mating effort", "Low embodied capital", "PPCS-6", "Sex drive", "Social anxiety")
desc <- merge(desc_m, desc_f, by="name")
desc <- cbind(Variable, desc[, sort(names(desc))])
desc
library(lavaan)
setwd("C:/Users/Rebecca/Documents/GitHub/LPA_analysis")
library(tidyverse)
library(lavaan)
dat <- haven::read_spss(
"C:/Users/Rebecca/Documents/GitHub/LPA_analysis/data/data raw/dataE_clear5 2209.sav") %>% select(CASE, starts_with("Y")) %>%
select(CASE, ends_with("r"))
dat[, c("Y_proclSpeed_r", "Y_proclDui_r", "Y_proclRob_r", "Y_proclKill_r", "Y_proclProstitute_r",
"Y_proclRape_r", "Y_proclZoo_r", "Y_proclPublic_r", "Y_proclPornChild_r",
"Y_proclPornChildDarknet_r", "Y_proclChatChild_r", "Y_proclGiftChild_r", "Y_proclSexChild_r",
"Y_proclPornYp_r", "Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclSexYp_r")] <-
lapply(dat[, c("Y_proclSpeed_r", "Y_proclDui_r", "Y_proclRob_r", "Y_proclKill_r", "Y_proclProstitute_r",
"Y_proclRape_r", "Y_proclZoo_r", "Y_proclPublic_r", "Y_proclPornChild_r",
"Y_proclPornChildDarknet_r", "Y_proclChatChild_r", "Y_proclGiftChild_r", "Y_proclSexChild_r",
"Y_proclPornYp_r", "Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclSexYp_r")], ordered)
mod <- "
child =~ Y_proclPornChild_r  + Y_proclChatChild_r
+ Y_proclGiftChild_r + Y_proclPornChildDarknet_r
YP =~ Y_proclPornYp_r + Y_proclChatYp_r + Y_proclGiftYp_r + Y_proclSexYp_r
sex =~ child + YP + Y_proclRape_r + Y_proclZoo_r + Y_proclPublic_r + Y_proclProstitute_r+ Y_proclSexChild_r
child ~~ 0*YP
sex ~~ 1*sex
"
fit_mod <- sem(mod, dat, ordered=c("Y_proclSpeed_r", "Y_proclDui_r", "Y_proclRob_r", "Y_proclKill_r", "Y_proclProstitute_r",
"Y_proclRape_r", "Y_proclZoo_r", "Y_proclPublic_r", "Y_proclPornChild_r",
"Y_proclPornChildDarknet_r", "Y_proclChatChild_r", "Y_proclGiftChild_r", "Y_proclSexChild_r",
"Y_proclPornYp_r", "Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclSexYp_r"))
summary(fit_mod, fit.measures=T, standardized=T)
mod <- "
child =~ Y_proclPornChild_r  + Y_proclChatChild_r
+ Y_proclGiftChild_r + Y_proclPornChildDarknet_r
YP =~ Y_proclPornYp_r + Y_proclChatYp_r + Y_proclGiftYp_r + Y_proclSexYp_r
sex =~ child + YP + Y_proclRape_r + Y_proclZoo_r + Y_proclPublic_r + Y_proclProstitute_r+ Y_proclSexChild_r
child ~~ 0*YP
sex ~~ 1*sex
child ~~0.001*child
"
fit_mod <- sem(mod, dat, ordered=c("Y_proclSpeed_r", "Y_proclDui_r", "Y_proclRob_r", "Y_proclKill_r", "Y_proclProstitute_r",
"Y_proclRape_r", "Y_proclZoo_r", "Y_proclPublic_r", "Y_proclPornChild_r",
"Y_proclPornChildDarknet_r", "Y_proclChatChild_r", "Y_proclGiftChild_r", "Y_proclSexChild_r",
"Y_proclPornYp_r", "Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclSexYp_r"))
summary(fit_mod, fit.measures=T, standardized=T)
mod <- "
child =~ Y_proclPornChild_r  + Y_proclChatChild_r
+ Y_proclGiftChild_r
YP =~ Y_proclPornYp_r + Y_proclChatYp_r + Y_proclGiftYp_r + Y_proclSexYp_r
sex =~ child + YP + Y_proclRape_r + Y_proclZoo_r + Y_proclPublic_r + Y_proclProstitute_r+ Y_proclSexChild_r
child ~~ 0*YP
sex ~~ 1*sex
child ~~0.001*child
"
fit_mod <- sem(mod, dat, ordered=c("Y_proclSpeed_r", "Y_proclDui_r", "Y_proclRob_r", "Y_proclKill_r", "Y_proclProstitute_r",
"Y_proclRape_r", "Y_proclZoo_r", "Y_proclPublic_r", "Y_proclPornChild_r",
"Y_proclPornChildDarknet_r", "Y_proclChatChild_r", "Y_proclGiftChild_r", "Y_proclSexChild_r",
"Y_proclPornYp_r", "Y_proclChatYp_r", "Y_proclGiftYp_r", "Y_proclSexYp_r"))
summary(fit_mod, fit.measures=T, standardized=T)
View(desc_m)
Variable <- c("Sexual interest in children", "CSBD-7", "LON", "Mating effort", "Low embodied capital", "PPCS-6", "Sex drive", "Social anxiety")
#Bind Variable column to the beginning
desc_m <- cbind(Variable, desc_m[, -1])
View(desc_m)
Scale <- c("Sexual interest in children", "CSBD-7", "LON", "Mating effort", "Low embodied capital", "PPCS-6", "Sex drive", "Social anxiety")
#Bind Variable column to the beginning
desc_m <- cbind(Variable, desc_m[, -1])
Scale <- c("Sexual interest in children", "CSBD-7", "LON", "Mating effort", "Low embodied capital", "PPCS-6", "Sex drive", "Social anxiety")
#Bind Variable column to the beginning
desc_m <- cbind(Variable, desc_m[, -1])
#Pretty output
flextable(desc_m, col_keys=-c("type", "missing", )) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
library(tidyverse)
Scale <- c("Sexual interest in children", "CSBD-7", "LON", "Mating effort", "Low embodied capital", "PPCS-6", "Sex drive", "Social anxiety")
#Bind Variable column to the beginning
desc_m <- cbind(Variable, desc_m[, -1])
#Pretty output
flextable(desc_m, col_keys=-c("type", "missing", )) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
library(flextable)
Scale <- c("Sexual interest in children", "CSBD-7", "LON", "Mating effort", "Low embodied capital", "PPCS-6", "Sex drive", "Social anxiety")
#Bind Variable column to the beginning
desc_m <- cbind(Variable, desc_m[, -1])
#Pretty output
flextable(desc_m, col_keys=-c("type", "missing", )) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
flextable(desc_m, col_keys=-c("type", "missing")) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
Scale <- c("Sexual interest in children", "CSBD-7", "LON", "Mating effort", "Low embodied capital", "PPCS-6", "Sex drive", "Social anxiety")
#Bind Variable column to the beginning
desc_m <- cbind(Scale, desc_m[, -1])
#Pretty output
flextable(desc_m %>% select=-c("type", "missing")) %>%
#Pretty output
flextable(desc_m %>% select=(-"type", -"missing")) %>%
#Pretty output
flextable(desc_m %>% select(-"type", -"missing")) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
#Pretty output
flextable(desc_m %>% select(-"type", -"missing")) %>%
v=function(x) format(x, nsmall=2)
flextable(desc_m %>% select(-"type", -"missing")) %>%
v=function(x) format(x, nsmall=2) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
#Pretty output
flextable(desc_m %>% select(-"type", -"missing")) %>%
set_formatter(v=function(x) format(x, nsmall=2)) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
#Pretty output
flextable(desc_m %>% select(-"type", -"missing")) %>%
set_formatter(v=function(x) round(x, digits=2)) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
#Pretty output
flextable(desc_m %>% select(-"type", -"missing")) %>%
set_formatter(v=function(x) round(x, digits=3)) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
#Pretty output
flextable(desc_m %>% select(-"type", -"missing")) %>%
set_formatter(v=function(x) format(x, nsmall=2)) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
#Pretty output
flextable(desc_m %>% select(-"type", -"missing")) %>%
set_formatter(v=function(x) format(round(x, 2), nsmall=2)) %>%
set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
theme_booktabs() %>%
autofit()
=======
#turn off scientific notification
options(scipen = 999)
lca_models_m_2.2 <- mx_lca(data=data_males %>% select(-CASE),5:7, run=TRUE, exhaustive=FALSE, checkHess=TRUE)
setwd("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis")
saveRDS(lca_models_m_2.2, "./out/lca_models_m_2.2.RDS")
lca_models_m_1 <- read_rds("./out/lca_models_m_2.1.RDS")
lca_models_m_2 <- read_rds(".out/lca_models_m_2.2.RDS")
lca_models_m_2 <- read_rds("./out/lca_models_m_2.2.RDS")
test <- c(lca_models_m_1, lca_models_m_2) %>% flatten()
test <- c(lca_models_m_1, lca_models_m_2)
View(test)
View(lca_models_m)
table_fit(test)
class_prob(lca_models_m[[3]])
class_prob(lca_models_m[[3]], "sum.posterior")
lca_models_m <- c(lca_models_m_1, lca_models_m_2)
lca_fit <- table_fit(lca_models_m) %>% select(Name, LL, n, Parameters, BIC, Entropy, prob_min, prob_max, n_min, np_ratio, np_local)
LR_lca_m <- lr_lmr(lca_models_m)
lca_final_model_m <- lca_models_m[[3]] #x is the class enumeration of choice
#Check results
table_LCA_m <- table_results(lca_final_model_m)
table_LCA_m
lca_final_model_m %>% summary()
#conditional item probabilities
prob_table_LCA_m <- table_prob(lca_final_model_m)
prob_table_LCA_m <- reshape(prob_table_LCA_m, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))
#class proportions
class_prob_lca_m <- class_prob(lca_final_model_m, "sum.posterior")
plot(lca_fit)
#class proportions
class_prob_lca_m
class_prob(lca_final_model_m, type="avg.mostlikely")
#Load precoded functions
source("./functions/D_matrix_modal.R")
source("./functions/modal_weights.R")
#First extract posterior probabilities for class assignment and most likely class membership
posteriors <- class_prob(lca_final_model_m, type="individual")$individual %>% as_tibble()
#Compute the inverse D matrix as in Bakk et al. (2013)
inverse_D <- solve(D_matrix_modal(posteriors))
#Extract a vector with the most likely class memberships
modal_assignments <- posteriors %>% select(predicted)
#Use the modal_weights function to create modal weights from the inverse_D matrix and combine the results in a tibble with the posterior probabilities of class membership and the most likely class membership.
BCH_expanded_dataframe <- tibble(posteriors, modal_weights(modal_assignments, inverse_D) %>% as_tibble())
colnames(BCH_expanded_dataframe) <- c("postprob_class_1", "postprob_class_2", "postprob_class_3", "modal_class", "modal_weight_1", "modal_weight_2", "modal_weight_3")
#Tidy up behind us
rm(modal_assignments, inverse_D, posteriors)
#Attach the CASE variable to our weighted dataframe.
BCH_expanded_dataframe <- BCH_expanded_dataframe %>% mutate(CASE = data_males$CASE)
BCH_expanded_dataframe <- BCH_expanded_dataframe %>% pivot_longer(cols=starts_with("modal_weight"), values_to = "modal_weight", names_to=NULL)
#Create a variable that encodes the assumed class assignments for the BCH analysis
BCH_expanded_dataframe <- BCH_expanded_dataframe %>% mutate(predicted_class = vctrs::vec_rep(1:3, nrow(data_males)))
#Create dummy variables from this variable
BCH_expanded_dataframe <- fastDummies::dummy_cols(BCH_expanded_dataframe, select_columns = "predicted_class")
#Combine the expanded dataframe with the outcome variables
BCH_expanded_dataframe <- BCH_expanded_dataframe %>% full_join(y=haven::read_spss("./data/data raw/dataE_clear5 2209.sav") %>% filter(gender == 2) %>% select(CASE, starts_with("Y_") & ends_with("r")) %>% mutate(CASE = CASE %>% as.numeric()),by="CASE")
#Set up a dataframe for the the outputs of the regression analysis. Each row corresponds to one item.
BCH_results <- tibble(outcomes = colnames(BCH_expanded_dataframe %>% select(starts_with("Y_"))))
#Fixing negative weights to zero or nigh-zero
BCH_expanded_dataframe <- BCH_expanded_dataframe %>% mutate(modal_weight_2 = case_when(BCH_expanded_dataframe$modal_weight < 0 ~ 0, .default = BCH_expanded_dataframe$modal_weight))
BCH_expanded_dataframe <- BCH_expanded_dataframe %>% mutate(modal_weight_3 = case_when(BCH_expanded_dataframe$modal_weight < 0 ~ 0.01, .default = BCH_expanded_dataframe$modal_weight))
#We prepare the model specifications for the Firth Regression to run.
outcomes <- BCH_expanded_dataframe %>% select(starts_with("Y_")) %>% colnames()
predictors <- BCH_expanded_dataframe %>% select(starts_with("predicted")) %>% select(-predicted_class, -predicted_class_1) %>% colnames() %>% paste(collapse=" + ")
models <- paste(outcomes, "~", predictors, sep=" ")
#Do Flic (Firths regression with intercept correction)for the models in the list with weights fixed to zero.
log_regs <- list()
for (i in 1:17){
log_regs[[i]] <- logistf::logistf(formula=models[i], data = BCH_expanded_dataframe, model=TRUE, weights=BCH_expanded_dataframe$modal_weight_2) %>% flic()
}
##Do Flic for the models in the list with weights fixed to 0.01
log_regs_min <- list()
for (i in 1:17){
log_regs_min[[i]] <- logistf::logistf(formula=models[i], data = BCH_expanded_dataframe, model=TRUE, weights=BCH_expanded_dataframe$modal_weight_3) %>% flic()
}
#Combine the results in a dataframe
BCH_results <- BCH_results %>% mutate(models = log_regs)
BCH_results <- BCH_results %>% mutate(models_0.01_weights = log_regs_min)
View(BCH_results)
lca_models_f %>% class()
lca_models_m %>% class()
test <- as(lca_models_m, "mixture_list")
lr_lmr(lca_final_model_m)
lr_lmr(lca_final_model_m, lca_models_m[[2]])
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/.RData")
View(BCH_results)
>>>>>>> Stashed changes
