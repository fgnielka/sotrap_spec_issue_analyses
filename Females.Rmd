---
title: "Females"
output: word_document
---

```{r setup & library, include=F, message=F, warning=F}
#Do not show code chunks in the knitted document
knitr::opts_chunk$set(echo=F, warning=F, message=F)

#For reproducible results
set.seed(100)

#Turn off scientific notification
options(scipen=999)

#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM", "MOTE", "flextable", "logistf")

#Load function to check whether required packages are installed & load required packages
source("./functions/check_required_packages.R")
check_required_packages(packages)
lapply(packages, require, character.only=T)

#Clean up
rm(packages)

#######ATTENTION!!!
#At this point we load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=F specifications in all code blocks will make that possible 
load(".RData")

##DATA##

#We use gender instead of sex. A 1 represents a female. We want to only grab females. 
data_females <- haven::read_spss("./data/data raw/dataE_2112.sav") %>% dplyr::select(gender, CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% filter(gender == 1) %>% dplyr::select(-gender)
```

# 1. Distributions of Motivational Risk Variables

```{r factor, eval=F}
#Re-coding for the female data. Be reminded that the cuts for the quantiles are likely different between males and females - keep that in mind while interpreting the LCAs!
f_factor <- lapply(data_females %>% select(-CASE, -attr, -CSBD, -PPCS_6),cut_number, n=4) %>% as.tibble()
f_factor <- lapply(f_factor, ordered) %>% as.tibble()
data_females <- cbind(data_females$CASE, f_factor, data_females$attr) %>% mutate(attr  = case_when(`data_females$attr` == 0 ~ "no attraction", `data_females$attr` > 0 ~ "some attraction"), CSBD = data_females$CSBD, PPCS_6 = data_females$PPCS_6)
data_females <- data_females %>% select(-`data_females$attr`)
data_females <- data_females %>% mutate(attr = attr %>% ordered())
colnames(data_females)[1]<-"CASE"

#Dichotomise CSBD, PPCS_6 because they have not enough cases per bin to cluster it in quantiles. The names of the factor levels show where the cut was set.
data_females <- data_females %>% mutate(PPCS_6 = cut_number(data_females$PPCS_6, n=2) %>% ordered(), CSBD = cut_number(data_females$CSBD, n=2) %>% ordered())

#Clean up
rm(f_factor)

#Descriptives for females
desc_f <- tidySEM::descriptives(data_females %>% select(-CASE))
desc_f <- desc_f %>% select(name, type, n, missing, unique, mode, mode_value, v)
```

Show violin plots of all distributions and quantiles.

```{r violin plots}
#create long data frame for plotting, including only the relevant variables
plotd_f <- data_females %>% select(CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% pivot_longer(cols=sexdrive2:attr, names_to="var", values_to="score")
#create a table with the quantiles for each variable (except CSBD & PPCS_6)
quant_f <- as.data.frame(t(do.call(rbind.data.frame, (lapply(c("lon", "meffort", "mvalue", "sexdrive2", "socialanx"), function(x){parse_number(gsub(",.*$", "", levels(cut_number(as.data.frame(data_females)[, x], 4))))})))))
#rename columns
colnames(quant_f) <- c("lon", "meffort", "mvalue", "sexdrive2", "socialanx")
#pivot for plotting
quant_f <- pivot_longer(quant_f, cols=lon:socialanx, names_to='var')
#add CSBD & PPCS_6 manually because they can only be dichotomised
quant_f <- rbind(quant_f, pivot_longer(as.data.frame(t(do.call(rbind.data.frame, (lapply(c("CSBD", "PPCS_6"), function(x){parse_number(gsub(",.*$", "", levels(cut_number(as.data.frame(data_females)[, x], 2))))}))))), cols=V1:V2, names_to='var'))
#rename variables
quant_f$var[quant_f$var=="V1"] <- "CSBD"
quant_f$var[quant_f$var=="V2"] <- "PPCS_6"
#call on function in other R script
source("./functions/flat_violin.R")
#plot
ggplot(plotd_f %>% filter(var!="attr"), aes(x=as.factor(var), y=score, fill=var)) +
  geom_flat_violin(scale="width") +
  scale_fill_grey(start=.5, end=.9, aesthetics = "fill") +
  geom_dotplot(binaxis="y", dotsize=.04, stackdir="down", binwidth=.3, position=position_nudge(-.025)) +
  geom_errorbar(data=quant_f, aes(x=as.factor(var), ymin=value, ymax=value, linetype="Quantiles"), inherit.aes=F, linewidth=.5, width=.3, position=position_nudge(x=.15)) +
  scale_linetype_manual(values="solid") +
  guides(linetype=guide_legend(""), fill="none") +
  scale_x_discrete(labels=c("CSBD"="Compulsive sex.", "lon"="Loneliness", "meffort"="Mating effort", "mvalue"="Mate value", "PPCS_6"="Probl. porn use", "sexdrive2"="Sex drive", "socialanx"="Social anxiety")) +
  labs(x="", y="Value") +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1, size=10))
#plot attraction to children separately
ggplot(plotd_f %>% filter(var=="attr"), aes(x=score)) +
  geom_bar() +
  theme_classic() +
  labs(x="Attraction to children", y="Count")
```

Show new descriptives after categorising the variables according to the quantiles.

```{r descriptives}
#Create vector with rownames
Scale <- c("Attraction to children", "Compulsive sex.", "Loneliness", "Mating effort", "Mate value", "Probl. porn use", "Sex drive", "Social anxiety")
#Bind Variable column to the beginning
desc_f <- cbind(Scale, desc_f[, -1])

#Pretty output
flextable(desc_f %>% select(-"type", -"missing")) %>%
  set_formatter(v=function(x) format(round(x, 2), nsmall=2),
                unique=function(x) format(round(x-1, 0), nsmall=0)) %>%
  set_header_labels(n="N", unique="Categories", mode="Mode", mode_value="Modal value", v="v") %>%
  theme_booktabs() %>%
  autofit()
```

# Latent Class Analysis

We redo the LCA with the subset of female participants. The cutoff values for fit indices obviously stay the same. It should be noted that two more variables needed to be dichotomised in the female sample, because they were also to skewed to form quantiles. Those were PPCS and CSBD.

## Class Enumeration

```{r LCA_females, eval=F}
#We carry on with a LCA on the female sample. We stay with a maximum of seven clusters.

lca_models_f <- mx_lca(data=data_females %>% select(-CASE), classes=1:7)

#If non-convergence. Use mxTryHardOrdinal()

lca_fit_f <- table_fit(lca_models_f) %>% select(Name, LL, n, Parameters, BIC, Entropy, prob_min, prob_max, n_min, np_ratio, np_local)

#Entropy coeffient shows that the classes are not well separated. https://doi.org/10.1177/009579842093093 recommend a value of at least .8 and state that an LCA with an entropy coefficient lower than .6 will be har to publish.

LR_lca_f <- lr_lmr(lca_models_f)

lca_final_model_f <- lca_models_f[[3]] #x is the class enumaration of choice

#Check results
table_LCA_f <- table_results(lca_final_model_f)

#conditional item probabilities
prob_table_LCA_f <- table_prob(lca_final_model_f)
prob_table_LCA_f <- reshape(prob_table_LCA_f, direction="wide", v.names="Probability", timevar="group", idvar = c("Variable", "Category"))

#class proportions
class_prob_lca_f <- class_prob(lca_final_model_f, "sum.posterior")
```

Show the BIC values for the different numbers of classes. It is best for three classes.

```{r scree_plot_f}
plot(lca_fit_f)
```

The following table shows how many participants are in which class.

```{r class_proportion}
flextable(as.data.frame(class_prob_lca_f)) %>% 
  theme_booktabs()
```

## Model Evaluation

Show the different fit indices for the different numbers of classes.

```{r showfittable_f}
flextable(lca_fit_f) %>%
  set_formatter(Entropy=function(x) format(round(x, 2), nsmall=2),
                prob_min=function(x) format(round(x, 2), nsmall=2),
                prob_max=function(x) format(round(x, 2), nsmall=2),
                n_min=function(x) format(round(x, 2), nsmall=2),
                np_ratio=function(x) format(round(x, 2), nsmall=2),
                np_local=function(x) format(round(x, 2), nsmall=2)) %>%
  set_header_labels(Name="Number of classes", LL="LogLikelihood", n="N", prob_min="Min prob", prob_max="Max prob", n_min="Min n", np_ratio="NP ratio", np_local="Local NP") %>%
  theme_booktabs() %>%
  autofit()
```

<!--AvePP by Most Likely Class for Females
```{r avePP_f, eval=F}
class_prob(lca_final_model_f, type="avg.mostlikely")
```
-->

## Model Interpretation

The table and plot show the conditional item probabilities for the three-class model. 

```{r prob_table_f}
#Make table presentable
prob_table_LCA_f$Variable <- c(rep(c("Sex drive", "Mating effort", "Social anxiety", "Loneliness", "Mate value"), each=4), "Attraction to children", "Attraction to children", "Compulsive sex.", "Compulsive sex.", "Probl. porn use", "Probl. porn use")
#Pretty display
flextable(prob_table_LCA_f) %>%
  set_formatter(Probability.class1=function(x) format(round(x, 2), nsmall=2),
                Probability.class2=function(x) format(round(x, 2), nsmall=2),
                Probability.class3=function(x) format(round(x, 2), nsmall=2)) %>%
  set_header_labels(Probability.class1="Class 1", Probability.class2="Class 2", Probability.class3="Class 3") %>%
  theme_booktabs() %>%
  autofit()
```

```{r prob_plot_f, fig.width=12}
plot_prob(lca_final_model_f) +
  scale_fill_grey(start = 0.9, end = 0.5, aesthetics = "fill") +
  scale_x_discrete(labels=c("attr"="Attraction to children", "CSBD"="Compulsive sex.", "lon"="Loneliness", "meffort"="Mating effort", "mvalue"="Mate value", "PPCS_6"="Probl. porn use", "sexdrive2"="Sex drive", "socialanx"="Social anxiety")) +
  labs(x="") +
  theme_classic() +
  theme(axis.text.x=element_text(angle=65, hjust=1, size=10))
```

The classes look very similar to those for the male participants. Class 1 is similar to the "high risk" class, class 2 is similar to the "high mate value" class, and class 3 is similar to the "social incompetence" class.

# Distal Outcomes Analyses

```{r BCH_dataframe, eval=F}
#Load precoded functions
source("./functions/D_matrix_modal.R")
source("./functions/modal_weights.R")

#Creating a dataframe with modal weights
#First, extract posterior probabilities for class assignment and most likely class membership
posteriors_f <- class_prob(lca_final_model_f, type="individual")$individual %>% as_tibble()

#Compute the inverse D matrix as in Bakk et al. (2013)
inverse_D_f <- solve(D_matrix_modal(posteriors_f))

#Extract a vector with the most likely class memberships
modal_assignments_f <- posteriors_f %>% select(predicted)

#Use the modal_weights function to create modal weights from the inverse_D matrix and combine the results in a tibble with the posterior probabilities of class membership and the most likely class membership.
BCH_expanded_dataframe_f <- tibble(posteriors_f, modal_weights(modal_assignments_f, inverse_D_f) %>% as_tibble())
colnames(BCH_expanded_dataframe_f) <- c("postprob_class_1", "postprob_class_2", "postprob_class_3", "modal_class", "modal_weight_1", "modal_weight_2", "modal_weight_3")

#Clean up
rm(modal_assignments_f, inverse_D_f, posteriors_f)

#Attach the CASE variable to our weighted dataframe. 
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(CASE = data_females$CASE)

#We convert the expanded data frame from wide in long format, so that we can use it as an input for our further analyses. According to Bakk et al. (2016), each participant enters the analysis nclass times, each time differently weighted according to her class assignment. 
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% pivot_longer(cols=starts_with("modal_weight"), values_to = "modal_weight", names_to=NULL)

#Create a variable that encodes the assumed class assignments for the BCH analysis
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(predicted_class = vctrs::vec_rep(1:3, nrow(data_females)))

#Create dummy variables from this variable
BCH_expanded_dataframe_f <- fastDummies::dummy_cols(BCH_expanded_dataframe_f, select_columns = "predicted_class")

#Combine the expanded dataframe with the outcome variables
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% full_join(y=haven::read_spss("./data/data raw/dataE_clear5 2209.sav") %>% filter(gender == 1) %>% select(CASE, starts_with("Y_") & ends_with("r")) %>% mutate(CASE = CASE %>% as.numeric()), by="CASE")

#The Regression estimation appears to be not working with negative weights. I do not understand why this is neccessarily the case. We approach to ad-hoc solutions: 1. Fixing the negative weights to zero, 2. We fix the negative weights to 0.01. 

#Fixing negative weights to zero or nigh-zero
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_2 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0, .default = BCH_expanded_dataframe_f$modal_weight))
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_3 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0.01, .default = BCH_expanded_dataframe_f$modal_weight))

#We prepare the model specifications for the Firth Regression to run.
outcomes_f <- BCH_expanded_dataframe_f %>% select(starts_with("Y_")) %>% colnames()
predictors_f <- BCH_expanded_dataframe_f %>% select(starts_with("predicted")) %>% select(-predicted_class, -predicted_class_1) %>% colnames() %>% paste(collapse=" + ")
models_f <- paste(outcomes_f, "~", predictors_f, sep=" ")

#Do Flic (Firth's regression with intercept correction) for the models in the list with weights fixed to zero.
log_regs_f <- list()
for (i in 1:17){
  log_regs_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_2) %>% flic()
}

##Do Flic for the models in the list with weights fixed to 0.01
log_regs_min_f <- list()
for (i in 1:17){
  log_regs_min_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, control = logistf.control(fit="IRLS"), model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_3) %>% flic()
}

#Set up a dataframe for the the outputs of the regression analysis. Each row corresponds to one item.
BCH_results_f <- tibble(outcomes = c(colnames(BCH_expanded_dataframe_f %>% select(starts_with("Y_")))))

#Combine the results in a dataframe
BCH_results_f <- BCH_results_f %>% mutate(models = log_regs_f)
BCH_results_f <- BCH_results_f %>% mutate(models_0.01_weights = log_regs_min_f)

#Because of the case weights we have to test the parameters manually via likelihood ratio tests
BCH_results_f <- BCH_results_f %>% mutate(
lr_1 = lapply(BCH_results_f$models, logistftest, test=1,
              weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_2 = lapply(BCH_results_f$models, logistftest, test=2,
              weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_3 = lapply(BCH_results_f$models, logistftest, test=3,
              weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_total = lapply(BCH_results_f$models, logistftest, weights=BCH_expanded_dataframe_f$modal_weight_2, control=logistf.control(maxit=10000))) #We get a warning: Maximum number of iterations for null model exceeded. Neither increasing the maximum number of iterations nor using a different start value (by changing the seed) help.

BCH_results_f <- BCH_results_f %>% mutate(
lr_1_0.01 = lapply(BCH_results_f$models, logistftest, test=1,
                   weights=BCH_expanded_dataframe_f$modal_weight_3, 
                   control = logistf.control(fit="IRLS")),
lr_2_0.01 = lapply(BCH_results_f$models, logistftest, test=2,
                   weights=BCH_expanded_dataframe_f$modal_weight_3, 
                   control = logistf.control(fit="IRLS")),
lr_3_0.01 = lapply(BCH_results_f$models, logistftest, test=3,
                   weights=BCH_expanded_dataframe_f$modal_weight_3, 
                   control = logistf.control(fit="IRLS")),
lr_total_0.01 = lapply(BCH_results_f$models, logistftest,
                       weights=BCH_expanded_dataframe_f$modal_weight_3, 
                       control = logistf.control(fit="IRLS")))

#We extract p-values from the likelihood ratio tests. 
BCH_results_f <- BCH_results_f %>% mutate(
  p_1=lapply(BCH_results_f$lr_1, function(x){x$prob}) %>% unlist(),
  p_2=lapply(BCH_results_f$lr_2, function(x){x$prob}) %>% unlist(),
  p_3=lapply(BCH_results_f$lr_3, function(x){x$prob}) %>% unlist(),
  p_1_0.01=lapply(BCH_results_f$lr_1_0.01, function(x){x$prob}) %>% unlist(),
  p_2_0.01=lapply(BCH_results_f$lr_2_0.01, function(x){x$prob}) %>% unlist(),
  p_3_0.01=lapply(BCH_results_f$lr_3_0.01, function(x){x$prob}) %>% unlist(),
)

#Order BCH_results
BCH_results_f <- BCH_results_f[order(BCH_results_f$outcomes),]

#Add parameter estimates
#How to index the results_parameters table:
#All regression weights start with "b",
#All model output from the 0.01 weighted regression ends with "_0.01"
#All lower confidence interval limits begin with ci_l
#All upper confidence interval limits begin with ci_r
#All lr-test p-values start with p_lr
#Use tidyverse select functions 

BCH_results_parameters_f <- tibble(outcomes = BCH_results_f$outcomes, 
                                b_intercept = lapply(BCH_results_f$models, function(x){x$coefficients[1]}) %>% unlist(),
                                b_predicted_class_2 = lapply(BCH_results_f$models, function(x){x$coefficients[2]}) %>% unlist(),
                                b_predicted_class_3 =lapply(BCH_results_f$models, function(x){x$coefficients[3]}) %>% unlist(),
                                b_intercept_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[1]}) %>%
                                  unlist(),
                                b_predicted_class_2_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[2]}) %>%
                                  unlist(),
                                b_predicted_class_3_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[3]}) %>%
                                  unlist(),
                                ci_l_intercept = lapply(BCH_results_f$models, function(x){x$ci.lower[1]}) %>% unlist(),
                                ci_l_predicted_class_2 =lapply(BCH_results_f$models, function(x){x$ci.lower[2]}) %>% unlist(),
                                ci_l_predicted_class_3 =lapply(BCH_results_f$models, function(x){x$ci.lower[3]}) %>% unlist(),
                                ci_l_intercept_0.01= lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[1]}) %>% unlist(),
                                ci_l_predicted_class_2_0.01=lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[2]}) %>%
                                  unlist(),
                                ci_l_predicted_class_3_0.01=lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[3]}) %>%
                                  unlist(),
                                ci_r_intercept =lapply(BCH_results_f$models, function(x){x$ci.upper[1]}) %>% unlist(),
                                ci_r_predicted_class_2=lapply(BCH_results_f$models, function(x){x$ci.upper[2]}) %>% unlist(),
                                ci_r_predicted_class_3=lapply(BCH_results_f$models, function(x){x$ci.upper[3]}) %>% unlist(),
                                ci_r_intercept_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[1]}) %>% unlist(),
                                ci_r_predicted_class_2_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[2]}) %>%
                                  unlist(),
                                ci_r_predicted_class_3_0.01  = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[3]}) %>%
                                  unlist(),
                                p_lr_intercept = lapply(BCH_results_f$lr_1, function(x){x$prob}) %>% unlist(),
                                p_lr_predicted_class_2 = lapply(BCH_results_f$lr_2, function(x){x$prob}) %>% unlist(),
                                p_lr_predicted_class_3 = lapply(BCH_results_f$lr_3, function(x){x$prob}) %>% unlist(),
                                p_lr_intercept_0.01 = lapply(BCH_results_f$lr_1_0.01, function(x){x$prob}) %>% unlist(),
                                p_lr_predicted_class_2_0.01 = lapply(BCH_results_f$lr_2_0.01, function(x){x$prob}) %>% unlist(),
                                p_lr_predicted_class_3_0.01 = lapply(BCH_results_f$lr_3_0.01, function(x){x$prob}) %>% unlist(),
                                p_lr_total = lapply(BCH_results_f$lr_total, function(x){x$prob}) %>% unlist(),
                                p_lr_total_0.01 = lapply(BCH_results_f$lr_total_0.01, function(x){x$prob}) %>% unlist())

# #Save output to RDS.
# BCH_results_f %>% saveRDS(file="./out/BCH_results_f.RDS")
# 
# #Save Parameters Table to RDS
# BCH_results_parameters_f %>% saveRDS(file="./out/BCH_results_parameters_f.RDS")
```

Predicted class 1 was chosen as the reference class because it can be interpreted as the "high risk" class.

```{r show_BCH_results}
#Put relevant results in a table
results_f <- cbind(Proclivity = c("Flirting or having sexual conversations via chat or webcam with a child", #1
                                "Flirting or having sexual conversations via chat or webcam with a young person", #2
                                "Driving under the influence of drugs/alcohol", #3
                                "Paying or giving gifts to a child for online sexual material (for example, videos, images, or online streaming)", #4
                                "Paying or giving gifts to a young person for online sexual material (for example, videos, images, or online streaming", #5
                                "Killing someone", #6
                                "Watching porn depicting a child", #7
                                "Watching porn depicting a child on the Darknet", #8
                                "Watching porn depicting a young person", #9
                                "Engaging in sexual activity with a prostitute", #10
                                "Watching porn in public spaces such as a bus or library", #11
                                "Engaging in sexual activity with an adult who does not agree or is not able to agree, for example, due to intoxication", #12
                                "Robbing a bank", #13
                                "Having offline sex or sexual contact with a child", #14
                                "Having offline sex or sexual contact with a young person", #15
                                "Driving faster than the posted speed limit", #16
                                "Engaging in sexual activity with an animal"), #17
                 BCH_results_parameters_f %>%
                 select(ends_with("total_0.01"), starts_with("b") & ends_with("0.01"), starts_with("p") & ends_with("0.01")))
#Add odds for each class
results_f <- results_f %>% mutate(odds_predicted_class_2_0.01 = exp(results_f$b_intercept_0.01)*exp(results_f$b_predicted_class_2_0.01), 
                              odds_predicted_class_3_0.01 = exp(results_f$b_intercept_0.01)*exp(results_f$b_predicted_class_3_0.01),
                              odds_predicted_class_1_0.01 = exp(results_f$b_intercept_0.01))
#Change order of rows for unity with other tables
results_f <- results_f[c(10, 11, 12, 17, 7, 8, 1, 4, 14, 9, 2, 5, 15, 16, 3, 13, 6),]
#Pretty output
flextable(results_f, col_keys=c("Proclivity", "p_lr_total_0.01", "b_intercept_0.01", "p_lr_intercept_0.01", "b_predicted_class_2_0.01", "p_lr_predicted_class_2_0.01", "b_predicted_class_3_0.01", "p_lr_predicted_class_3_0.01")) %>% 
  set_formatter(p_lr_total_0.01=function(x) apa(x, decimals=3, leading=F), 
                b_intercept_0.01=function(x) format(round(exp(x), 2), nsmall=2), #transform into OR with exp()
                p_lr_intercept_0.01=function(x) apa(x, decimals=3, leading=F),
                b_predicted_class_2_0.01=function(x) format(round(exp(x), 2), nsmall=2), 
                p_lr_predicted_class_2_0.01=function(x) apa(x, decimals=3, leading=F),
                b_predicted_class_3_0.01=function(x) format(round(exp(x), 2), nsmall=2), 
                p_lr_predicted_class_3_0.01=function(x) apa(x, decimals=3, leading=F)) %>%
  set_header_labels(p_lr_total_0.01="p", b_intercept_0.01="Odds", p_lr_intercept_0.01="p", b_predicted_class_2_0.01="OR", p_lr_predicted_class_2_0.01="p", b_predicted_class_3_0.01="OR", p_lr_predicted_class_3_0.01="p") %>%
  add_header_row(values=c("", "Global LRT", "(Intercept)", "Class 2", "Class 3"), colwidths=c(1, 1, 2, 2, 2)) %>% 
  theme_booktabs() %>%
  autofit()
```

```{r plot_proclivities}
#rename proclivities for plotting
procl <- c("Prostitute", "Public porn", "Rape", "Zoophilia", "Porn child", "Porn child darknet", "Chat child", "Gift child", "Sex child", "Porn YP", "Chat YP", "Gift YP", "Sex YP", "Speed", "DUI", "Rob", "Kill")
#Rename proclivities
plot_results_f <- results_f
plot_results_f$Proclivity <- procl
#Factorise items
plot_results_f$Proclivity <- factor(plot_results_f$Proclivity, levels=plot_results_f$Proclivity)
#Pivot results table for plotting
#Only odds < 1 for better scaling
plot_results_f <- plot_results_f %>% 
  select(Proclivity, starts_with("odds")) %>% 
  filter(odds_predicted_class_1_0.01 < 1 & odds_predicted_class_2_0.01 < 1 & odds_predicted_class_3_0.01 < 1) %>% 
  pivot_longer(cols=starts_with("odds"), names_to="class", values_to="odds") 
#Rename class column
plot_results_f$class <- rep(c(2, 3, 1), nrow(plot_results_f)/3)
#Remaining odds > 1
#Rename
plot_results_2_f <- results_f
plot_results_2_f$Proclivity <- procl
#Factorise
plot_results_2_f$Proclivity <- factor(plot_results_2_f$Proclivity, levels=plot_results_2_f$Proclivity)
#Pivot
plot_results_2_f <- plot_results_2_f %>% 
  select(Proclivity, starts_with("odds")) %>% 
  filter(odds_predicted_class_1_0.01 > 1 | odds_predicted_class_2_0.01 > 1 | odds_predicted_class_3_0.01 > 1) %>% 
  pivot_longer(cols=starts_with("odds"), names_to="class", values_to="odds") 
#Rename class column
plot_results_2_f$class <- rep(c(2, 3, 1), nrow(plot_results_2_f)/3)

#Line plots
#Odds < 1
ggplot(plot_results_f, aes(x=Proclivity, y=odds, group=as.factor(class), linetype=as.factor(class))) +
  geom_line() +
  geom_point(aes(shape=as.factor(class))) +
  scale_linetype_manual(name=NULL, values=c("solid", "dotted", "dashed"), labels=c("Class 1", "Class 2", "Class 3")) +
  scale_shape_manual(name=NULL, values=c(0, 3, 1), labels=c("Class 1", "Class 2", "Class 3")) +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1, size=8))
#Odds > 1
ggplot(plot_results_2_f, aes(x=Proclivity, y=odds, group=as.factor(class), linetype=as.factor(class))) +
  geom_line() +
  geom_point(aes(shape=as.factor(class))) +
  scale_linetype_manual(name=NULL, values=c("solid", "dotted", "dashed"), labels=c("Class 1", "Class 2", "Class 3")) +
  scale_shape_manual(name=NULL, values=c(0, 3, 1), labels=c("Class 1", "Class 2", "Class 3")) +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1, size=8))
```
*Note.* Prostitute = "Engaging in sexual activity with a prostitute"; Public porn = "Watching porn in public spaces such as a bus or library", Rape = "Engaging in sexual activity with an adult who does not agree or is not able to agree, for example, due to intoxication", Zoophilia = "Engaging in sexual activity with an animal", Porn child = "Watching porn depicting a child", Porn child darknet = "Watching porn depicting a child on the Darknet", Chat child = "Flirting or having sexual conversations via chat or webcam with a child", Gift child = "Paying or giving gifts to a child for online sexual material (for example, videos, images, or online streaming)", Sex child = "Having offline sex or sexual contact with a child", Porn YP = "Watching porn depicting a young person", Chat YP = "Flirting or having sexual conversations via chat or webcam with a young person", Gift YP = "Paying or giving gifts to a young person for online sexual material (for example, videos, images, or online streaming", Sex YP = "Having offline sex or sexual contact with a young person", Kill = "Killing someone", Speed = "Driving faster than the posted speed limit", DUI = "Driving under the influence of drugs/alcohol", Rob = "Robbing a bank"



