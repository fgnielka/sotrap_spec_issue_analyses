#######ATTENTION!!!
#At this point we load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=F specifications in all code blocks will make that possible
load(".RData")
View(m_factor)
View(data_males)
View(plot_results)
View(plot_results_2)
View(plot_results_2)
View(results)
View(log_regs)
View(log_regs)
rm(BCH_expanded_dataframe_f, BCH_results_f, class_long, class_longa, class_prb_lca_f, data_females, desc_f, f_factor, lca_final_model, lca_final_model_f, lca_fit_f, lca_models_f, lca_models_m_1, lca_models_m_2, lca_models_m_2.2, log_regs_f, log_regs_min_f, LR_lca_f, m_factor, plot_results, plot_results_2, prob_table_LCA_f, Ptable, table_LCA_f, test, test1, test2)
rm(class_prob_lca_f)
View(LR_lca_m)
rm(LR_lca_m)
View(table_LCA_m)
View(results)
save.image("C:/Users/gniel/OneDrive - MSB Medical School Berlin/Project special issue/LPA_analysis/mens' analysis/.RData")
#Load RData file with all files for the females analysis.
load("./.RData")
#Load RData file with all files for the females analysis.
load("./.RData")
#Load precoded functions
source("./functions/D_matrix_modal.R")
source("./functions/modal_weights.R")
#Creating a dataframe with modal weights
#First, extract posterior probabilities for class assignment and most likely class membership
posteriors_f <- class_prob(lca_final_model_f, type="individual")$individual %>% as_tibble()
#Load RData file with all files for the females analysis.
load("./.RData")
#Do not show code chunks in the knitted document
knitr::opts_chunk$set(echo=F, warning=F, message=F)
#For reproducible results
set.seed(100)
#Turn off scientific notification
options(scipen=999)
#Declare vector of required packages
packages <- c("tidyverse", "readr", "tidySEM", "MOTE", "flextable", "logistf")
#Load function to check whether required packages are installed & load required packages
source("./functions/check_required_packages.R")
check_required_packages(packages)
lapply(packages, require, character.only=T)
#Clean up
rm(packages)
#######ATTENTION!!!
#At this point we load a pre-saved .RData file in which the environment is saved. That makes the code less reproducible, but removing the eval=F specifications in all code blocks will make that possible
#load(".RData")
##DATA##
#We use gender instead of sex. A 1 represents a female. We want to only grab females.
data_females <- haven::read_spss("./data/data raw/dataE_2112.sav") %>% dplyr::select(gender, CASE, sexdrive2, CSBD, PPCS_6, meffort, socialanx, lon, mvalue, attr) %>% filter(gender == 1) %>% dplyr::select(-gender)
#Load precoded functions
source("./functions/D_matrix_modal.R")
source("./functions/modal_weights.R")
#Creating a dataframe with modal weights
#First, extract posterior probabilities for class assignment and most likely class membership
posteriors_f <- class_prob(lca_final_model_f, type="individual")$individual %>% as_tibble()
#Compute the inverse D matrix as in Bakk et al. (2013)
inverse_D_f <- solve(D_matrix_modal(posteriors_f))
#Extract a vector with the most likely class memberships
modal_assignments_f <- posteriors_f %>% select(predicted)
#Use the modal_weights function to create modal weights from the inverse_D matrix and combine the results in a tibble with the posterior probabilities of class membership and the most likely class membership.
BCH_expanded_dataframe_f <- tibble(posteriors_f, modal_weights(modal_assignments_f, inverse_D_f) %>% as_tibble())
colnames(BCH_expanded_dataframe_f) <- c("postprob_class_1", "postprob_class_2", "postprob_class_3", "modal_class", "modal_weight_1", "modal_weight_2", "modal_weight_3")
#Clean up
rm(modal_assignments_f, inverse_D_f, posteriors_f)
#Attach the CASE variable to our weighted dataframe.
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(CASE = data_females$CASE)
#We convert the expanded data frame from wide in long format, so that we can use it as an input for our further analyses. According to Bakk et al. (2016), each participant enters the analysis nclass times, each time differently weighted according to her class assignment.
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% pivot_longer(cols=starts_with("modal_weight"), values_to = "modal_weight", names_to=NULL)
#Create a variable that encodes the assumed class assignments for the BCH analysis
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(predicted_class = vctrs::vec_rep(1:3, nrow(data_females)))
#Create dummy variables from this variable
BCH_expanded_dataframe_f <- fastDummies::dummy_cols(BCH_expanded_dataframe_f, select_columns = "predicted_class")
#Combine the expanded dataframe with the outcome variables
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% full_join(y=haven::read_spss("./data/data raw/dataE_clear5 2209.sav") %>% filter(gender == 1) %>% select(CASE, starts_with("Y_") & ends_with("r")) %>% mutate(CASE = CASE %>% as.numeric()), by="CASE")
#The Regression estimation appears to be not working with negative weights. I do not understand why this is neccessarily the case. We approach to ad-hoc solutions: 1. Fixing the negative weights to zero, 2. We fix the negative weights to 0.01.
#Fixing negative weights to zero or nigh-zero
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_2 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0, .default = BCH_expanded_dataframe_f$modal_weight))
BCH_expanded_dataframe_f <- BCH_expanded_dataframe_f %>% mutate(modal_weight_3 = case_when(BCH_expanded_dataframe_f$modal_weight < 0 ~ 0.01, .default = BCH_expanded_dataframe_f$modal_weight))
#We prepare the model specifications for the Firth Regression to run.
outcomes_f <- BCH_expanded_dataframe_f %>% select(starts_with("Y_")) %>% colnames()
predictors_f <- BCH_expanded_dataframe_f %>% select(starts_with("predicted")) %>% select(-predicted_class, -predicted_class_1) %>% colnames() %>% paste(collapse=" + ")
models_f <- paste(outcomes_f, "~", predictors_f, sep=" ")
#Do Flic (Firth's regression with intercept correction) for the models in the list with weights fixed to zero.
log_regs_f <- list()
for (i in 1:17){
log_regs_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_2) %>% flic()
}
##Do Flic for the models in the list with weights fixed to 0.01
log_regs_min_f <- list()
for (i in 1:17){
log_regs_min_f[[i]] <- logistf::logistf(formula=models_f[i], data = BCH_expanded_dataframe_f, control = logistf.control(fit="IRLS"), model=TRUE, weights=BCH_expanded_dataframe_f$modal_weight_3) %>% flic()
}
#Set up a dataframe for the the outputs of the regression analysis. Each row corresponds to one item.
BCH_results_f <- tibble(outcomes = c(colnames(BCH_expanded_dataframe_f %>% select(starts_with("Y_")))))
#Combine the results in a dataframe
BCH_results_f <- BCH_results_f %>% mutate(models = log_regs_f)
BCH_results_f <- BCH_results_f %>% mutate(models_0.01_weights = log_regs_min_f)
#Because of the case weights we have to test the parameters manually via likelihood ratio tests
BCH_results_f <- BCH_results_f %>% mutate(
lr_1 = lapply(BCH_results_f$models, logistftest, test=1,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_2 = lapply(BCH_results_f$models, logistftest, test=2,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_3 = lapply(BCH_results_f$models, logistftest, test=3,
weights=BCH_expanded_dataframe_f$modal_weight_2),
lr_total = lapply(BCH_results_f$models, logistftest, weights=BCH_expanded_dataframe_f$modal_weight_2, control=logistf.control(maxit=10000))) #We get a warning: Maximum number of iterations for null model exceeded. Neither increasing the maximum number of iterations nor using a different start value (by changing the seed) help.
BCH_results_f <- BCH_results_f %>% mutate(
lr_1_0.01 = lapply(BCH_results_f$models, logistftest, test=1,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")),
lr_2_0.01 = lapply(BCH_results_f$models, logistftest, test=2,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")),
lr_3_0.01 = lapply(BCH_results_f$models, logistftest, test=3,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")),
lr_total_0.01 = lapply(BCH_results_f$models, logistftest,
weights=BCH_expanded_dataframe_f$modal_weight_3,
control = logistf.control(fit="IRLS")))
#We extract p-values from the likelihood ratio tests.
BCH_results_f <- BCH_results_f %>% mutate(
p_1=lapply(BCH_results_f$lr_1, function(x){x$prob}) %>% unlist(),
p_2=lapply(BCH_results_f$lr_2, function(x){x$prob}) %>% unlist(),
p_3=lapply(BCH_results_f$lr_3, function(x){x$prob}) %>% unlist(),
p_1_0.01=lapply(BCH_results_f$lr_1_0.01, function(x){x$prob}) %>% unlist(),
p_2_0.01=lapply(BCH_results_f$lr_2_0.01, function(x){x$prob}) %>% unlist(),
p_3_0.01=lapply(BCH_results_f$lr_3_0.01, function(x){x$prob}) %>% unlist(),
)
#Order BCH_results
BCH_results_f <- BCH_results_f[order(BCH_results_f$outcomes),]
#Add parameter estimates
#How to index the results_parameters table:
#All regression weights start with "b",
#All model output from the 0.01 weighted regression ends with "_0.01"
#All lower confidence interval limits begin with ci_l
#All upper confidence interval limits begin with ci_r
#All lr-test p-values start with p_lr
#Use tidyverse select functions
BCH_results_parameters_f <- tibble(outcomes = BCH_results_f$outcomes,
b_intercept = lapply(BCH_results_f$models, function(x){x$coefficients[1]}) %>% unlist(),
b_predicted_class_2 = lapply(BCH_results_f$models, function(x){x$coefficients[2]}) %>% unlist(),
b_predicted_class_3 =lapply(BCH_results_f$models, function(x){x$coefficients[3]}) %>% unlist(),
b_intercept_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[1]}) %>%
unlist(),
b_predicted_class_2_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[2]}) %>%
unlist(),
b_predicted_class_3_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$coefficients[3]}) %>%
unlist(),
ci_l_intercept = lapply(BCH_results_f$models, function(x){x$ci.lower[1]}) %>% unlist(),
ci_l_predicted_class_2 =lapply(BCH_results_f$models, function(x){x$ci.lower[2]}) %>% unlist(),
ci_l_predicted_class_3 =lapply(BCH_results_f$models, function(x){x$ci.lower[3]}) %>% unlist(),
ci_l_intercept_0.01= lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[1]}) %>% unlist(),
ci_l_predicted_class_2_0.01=lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[2]}) %>%
unlist(),
ci_l_predicted_class_3_0.01=lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.lower[3]}) %>%
unlist(),
ci_r_intercept =lapply(BCH_results_f$models, function(x){x$ci.upper[1]}) %>% unlist(),
ci_r_predicted_class_2=lapply(BCH_results_f$models, function(x){x$ci.upper[2]}) %>% unlist(),
ci_r_predicted_class_3=lapply(BCH_results_f$models, function(x){x$ci.upper[3]}) %>% unlist(),
ci_r_intercept_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[1]}) %>% unlist(),
ci_r_predicted_class_2_0.01 = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[2]}) %>%
unlist(),
ci_r_predicted_class_3_0.01  = lapply(BCH_results_f$models_0.01_weights, function(x){x$ci.upper[3]}) %>%
unlist(),
p_lr_intercept = lapply(BCH_results_f$lr_1, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_2 = lapply(BCH_results_f$lr_2, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_3 = lapply(BCH_results_f$lr_3, function(x){x$prob}) %>% unlist(),
p_lr_intercept_0.01 = lapply(BCH_results_f$lr_1_0.01, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_2_0.01 = lapply(BCH_results_f$lr_2_0.01, function(x){x$prob}) %>% unlist(),
p_lr_predicted_class_3_0.01 = lapply(BCH_results_f$lr_3_0.01, function(x){x$prob}) %>% unlist(),
p_lr_total = lapply(BCH_results_f$lr_total, function(x){x$prob}) %>% unlist(),
p_lr_total_0.01 = lapply(BCH_results_f$lr_total_0.01, function(x){x$prob}) %>% unlist())
# #Save output to RDS.
# BCH_results_f %>% saveRDS(file="./out/BCH_results_f.RDS")
#
# #Save Parameters Table to RDS
# BCH_results_parameters_f %>% saveRDS(file="./out/BCH_results_parameters_f.RDS")
save.image("C:/Users/Rebecca/Documents/GitHub/LPA_analysis/women's analysis/.RData")
